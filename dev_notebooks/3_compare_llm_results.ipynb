{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from juddges.llm_as_judge.data_model import PredictionLoader\n",
    "from juddges.llm_as_judge.result_loading import (\n",
    "    llm_as_judge_avg_scores,\n",
    "    ngram_avg_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dirs = [\n",
    "    \"data/experiments/predict/raw_vllm/pl_court_personal_rights/qwen_3_32b/info_extraction_annotated_json_refined/personal_rights/seed_42/\",\n",
    "    \"data/experiments/predict/raw_vllm/pl_court_personal_rights/qwen_3_8b/info_extraction_annotated_json_refined/personal_rights/seed_42/\",\n",
    "    \"data/experiments/predict/raw_vllm/pl_court_personal_rights/llama_3.1_8b_instruct/info_extraction_annotated_json_refined/personal_rights/seed_42/\",\n",
    "    # \"data/experiments/predict/raw_vllm/pl_court_swiss_franc_loans/llama_3.1_8b_instruct/info_extraction_annotated_json_refined/swiss_franc_loans_refined/seed_42\",\n",
    "    # \"data/experiments/predict/raw_vllm/pl_court_swiss_franc_loans/qwen_3_8b/info_extraction_annotated_json_refined/swiss_franc_loans_refined/seed_42\",\n",
    "    # \"data/experiments/predict/raw_vllm/pl_court_swiss_franc_loans/qwen_3_32b/info_extraction_annotated_json_refined/swiss_franc_loans_refined/seed_42\",\n",
    "]\n",
    "\n",
    "\n",
    "judge_resutls = {}\n",
    "ngram_results = {}\n",
    "for rdir in tqdm(res_dirs):\n",
    "    pred_loader = PredictionLoader(root_dir=rdir, judge_name=\"gpt-4.1-mini\")\n",
    "    preds = pred_loader.load_predictions(verbose=True)\n",
    "    try:\n",
    "        res_judge = llm_as_judge_avg_scores(pred_loader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {rdir}\")\n",
    "    else:\n",
    "        judge_resutls[pred_loader.config.llm.name] = res_judge\n",
    "\n",
    "    res_ngram = ngram_avg_scores(pred_loader)\n",
    "    ngram_results[pred_loader.config.llm.name] = res_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for llm_name, res_judge in judge_resutls.items():\n",
    "    llm_name = llm_name.split(\"/\")[-1]\n",
    "    mean_col = f\"{llm_name} (mean)\"\n",
    "    se_col = f\"{llm_name} (SE)\"\n",
    "    res_judge = res_judge.rename(columns={\"mean_judge_score\": mean_col, \"se_judge_score\": se_col})\n",
    "    dfs.append(res_judge)\n",
    "\n",
    "judge_df = pd.concat(dfs, axis=1)\n",
    "judge_df_mean = judge_df[[col for col in judge_df.columns if col.endswith(\"(mean)\")]]\n",
    "judge_df_se = judge_df[[col for col in judge_df.columns if col.endswith(\"(SE)\")]]\n",
    "judge_df_mean.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = list({col.split(\" \")[0] for col in judge_df.columns})\n",
    "\n",
    "formatted = {}\n",
    "for index, row in judge_df.iterrows():\n",
    "    formatted[index] = {}\n",
    "    for llm_name in llms:\n",
    "        mean = row[f'{llm_name} (mean)'] * 100\n",
    "        se = row[f'{llm_name} (SE)'] * 100\n",
    "        formatted[index][llm_name] = f\"{mean:.3f} ({se:.3f})\"\n",
    "\n",
    "print(pd.DataFrame.from_dict(formatted, orient=\"index\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_llm_mean = judge_df_mean.mean(axis=0) * 100\n",
    "per_llm_se = (judge_df_se.pow(2).sum(axis=0) / len(judge_df_se)**2).pow(1/2) * 100\n",
    "\n",
    "print(per_llm_mean.to_latex())\n",
    "print(per_llm_se.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for llm_name, res_ngram in ngram_results.items():\n",
    "    llm_name = llm_name.split(\"/\")[-1]\n",
    "    mean_col = f\"{llm_name} (mean)\"\n",
    "    se_col = f\"{llm_name} (SE)\"\n",
    "    res_ngram = res_ngram.rename(columns={\"ngram_metric_mean\": mean_col, \"ngram_metric_se\": se_col})\n",
    "    dfs.append(res_ngram)\n",
    "\n",
    "ngram_df = pd.concat(dfs, axis=1)\n",
    "ngram_df_mean = ngram_df[[col for col in ngram_df.columns if col.endswith(\"(mean)\")]]\n",
    "ngram_df_se = ngram_df[[col for col in ngram_df.columns if col.endswith(\"(SE)\")]]\n",
    "ngram_df_mean.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_llm_mean = ngram_df_mean.mean(axis=0) * 100\n",
    "per_llm_se = (ngram_df_se.pow(2).sum(axis=0) / len(ngram_df_se)**2).pow(1/2) * 100\n",
    "\n",
    "print(per_llm_mean.to_latex())\n",
    "print(per_llm_se.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juddges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
