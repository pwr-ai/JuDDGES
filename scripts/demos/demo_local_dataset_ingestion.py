#!/usr/bin/env python3
"""
Demo local dataset ingestion without external dependencies.
Shows how to ingest local parquet files into Weaviate.
"""

from pathlib import Path

import requests

WEAVIATE_URL = "http://localhost:8084"
API_KEY = "PQA2.12-**lafqf"
HEADERS = {"Authorization": f"Bearer {API_KEY}"}


def ingest_local_polish_sample():
    """Demonstrate ingesting a small sample from local Polish court data."""

    print("ğŸ›ï¸  LOCAL POLISH COURT DATA INGESTION DEMO")
    print("=" * 60)

    # Simulate what would be found in the parquet files
    # (In reality, these would be loaded from the actual parquet files)
    sample_polish_docs = [
        {
            "document_id": "PL_DISTRICT_2024_001",
            "court_name": "SÄ…d Rejonowy w GdaÅ„sku",
            "judgment_date": "2024-01-15T00:00:00Z",
            "docket_number": "II C 1234/2023",
            "document_type": "wyrok",
            "judges": ["MaÅ‚gorzata Kowalska", "Jan Nowak"],
            "legal_bases": ["art. 353Â¹ k.c.", "art. 471 k.c.", "art. 415 k.c."],
            "keywords": ["umowa", "odszkodowanie", "szkoda", "odpowiedzialnoÅ›Ä‡"],
            "full_text": """WYROK z dnia 15 stycznia 2024 r.

SÄ„DU REJONOWEGO W GDAÅƒSKU
II WydziaÅ‚ Cywilny

Sygn. akt II C 1234/2023

UZASADNIENIE:
SÄ…d po rozpoznaniu sprawy z powÃ³dztwa o zapÅ‚atÄ™ odszkodowania z tytuÅ‚u niewykonania umowy uznaÅ‚ Å¼Ä…dania powoda za zasadne w czÄ™Å›ci.

Zgodnie z art. 353Â¹ kodeksu cywilnego dÅ‚uÅ¼nik obowiÄ…zany jest do naprawienia szkody wynikÅ‚ej z niewykonania lub nienaleÅ¼ytego wykonania zobowiÄ…zania, chyba Å¼e niewykonanie lub nienaleÅ¼yte wykonanie jest nastÄ™pstwem okolicznoÅ›ci, za ktÃ³re dÅ‚uÅ¼nik odpowiedzialnoÅ›ci nie ponosi.

W niniejszej sprawie powÃ³d wykazaÅ‚, Å¼e pozwany nie wykonaÅ‚ umowy w terminie, co spowodowaÅ‚o konkretne straty po stronie powoda. Pozwany nie przedstawiÅ‚ dowodÃ³w na okolicznoÅ›Ä‡ zwalniajÄ…cÄ… go z odpowiedzialnoÅ›ci.""",
            "country": "Poland",
            "language": "pl",
            "court_type": "district",
            "judgment_type": "wyrok",
        },
        {
            "document_id": "PL_APPEAL_2024_002",
            "court_name": "SÄ…d OkrÄ™gowy w Warszawie",
            "judgment_date": "2024-02-20T00:00:00Z",
            "docket_number": "I ACa 567/2024",
            "document_type": "wyrok",
            "judges": ["Anna WiÅ›niewska", "Piotr Kowalczyk", "Maria ZieliÅ„ska"],
            "legal_bases": [
                "art. 385 k.c.",
                "art. 627 k.c.",
                "ustawa o ochronie konkurencji i konsumentÃ³w",
            ],
            "keywords": ["konsument", "klauzula abuzywna", "umowa", "ochrona"],
            "full_text": """WYROK z dnia 20 lutego 2024 r.

SÄ„DU OKRÄ˜GOWEGO W WARSZAWIE
I WydziaÅ‚ Cywilny OdwoÅ‚awczy

Sygn. akt I ACa 567/2024

W sprawie z odwoÅ‚ania od wyroku SÄ…du Rejonowego w sprawie uznania klauzuli umownej za abuzywnÄ….

UZASADNIENIE:
SÄ…d OkrÄ™gowy po rozpatrzeniu odwoÅ‚ania uznaÅ‚ je za bezzasadne i utrzymaÅ‚ w mocy wyrok SÄ…du pierwszej instancji.

Sporna klauzula umowna rzeczywiÅ›cie narusza rÃ³wnowagÄ™ kontraktowÄ… na niekorzyÅ›Ä‡ konsumenta, co jest niezgodne z przepisami ustawy o ochronie konkurencji i konsumentÃ³w oraz kodeksu cywilnego.

Zgodnie z orzecznictwem SÄ…du NajwyÅ¼szego, klauzule ograniczajÄ…ce prawa konsumenta w sposÃ³b nieproporcjonalny sÄ… niewaÅ¼ne.""",
            "country": "Poland",
            "language": "pl",
            "court_type": "regional",
            "judgment_type": "wyrok",
        },
        {
            "document_id": "PL_SUPREME_2024_003",
            "court_name": "SÄ…d NajwyÅ¼szy",
            "judgment_date": "2024-03-10T00:00:00Z",
            "docket_number": "III CZP 89/2023",
            "document_type": "uchwaÅ‚a",
            "judges": ["Prof. Jan Kowalski", "Dr Maria Nowak", "Dr Piotr WiÅ›niewski"],
            "legal_bases": ["art. 58 Â§ 1 k.c.", "art. 23 k.c.", "art. 24 k.c."],
            "keywords": ["prawa osobiste", "dobra osobiste", "ochrona", "zadoÅ›Ä‡uczynienie"],
            "full_text": """UCHWAÅA z dnia 10 marca 2024 r.

SÄ„DU NAJWYÅ»SZEGO
Izba Cywilna

Sygn. akt III CZP 89/2023

W przedmiocie zagadnienia prawnego dotyczÄ…cego zakresu ochrony dÃ³br osobistych w internecie.

UZASADNIENIE:
SÄ…d NajwyÅ¼szy po rozpoznaniu zagadnienia prawnego przedstawionego przez SÄ…d Apelacyjny w Krakowie przyjÄ…Å‚ nastÄ™pujÄ…cÄ… uchwaÅ‚Ä™:

Naruszenie dÃ³br osobistych przez publikacjÄ™ nieprawdziwych informacji w internecie uzasadnia roszczenie o zadoÅ›Ä‡uczynienie pieniÄ™Å¼ne, ktÃ³rego wysokoÅ›Ä‡ powinna uwzglÄ™dniaÄ‡ charakter naruszonego dobra, wagÄ™ naruszenia oraz jego skutki.

Przy ustalaniu wysokoÅ›ci zadoÅ›Ä‡uczynienia naleÅ¼y braÄ‡ pod uwagÄ™ zasiÄ™g publikacji oraz stopieÅ„ spoÅ‚ecznego oddziaÅ‚ywania medium internetowego.""",
            "country": "Poland",
            "language": "pl",
            "court_type": "supreme",
            "judgment_type": "uchwaÅ‚a",
        },
    ]

    print(f"ğŸ“Š Sample size: {len(sample_polish_docs)} documents")
    print("ğŸ“‚ Source: Local parquet files (data/datasets/pl/raw/)")
    print("ğŸ¯ Represents: Polish court hierarchy (District â†’ Regional â†’ Supreme)")

    # Show the mapping that would be automatically detected
    print("\nğŸ¤– AUTOMATIC FIELD MAPPING (Universal System)")
    print("-" * 50)

    mappings = [
        ("judgment_id", "document_id", "100%"),
        ("docket_number", "document_number", "100%"),
        ("judgment_date", "date_issued", "100%"),
        ("court_name", "court_name", "100%"),
        ("full_text", "full_text", "100%"),
        ("judges", "judges", "100%"),
        ("legal_bases", "legal_bases", "100%"),
        ("keywords", "keywords", "100%"),
        ("document_type", "judgment_type", "100%"),
        ("country", "country", "100%"),
        ("language", "language", "100%"),
    ]

    for source, target, confidence in mappings:
        print(f"  {source:<20} â†’ {target:<20} ({confidence} confidence)")

    # Create enhanced schema for Polish legal documents
    schema = {
        "class": "PolishLegalDocument",
        "description": "Polish court judgments with enhanced metadata",
        "properties": [
            {
                "name": "document_id",
                "dataType": ["text"],
                "description": "Unique judgment identifier",
            },
            {"name": "court_name", "dataType": ["text"], "description": "Polish court name"},
            {"name": "judgment_date", "dataType": ["date"], "description": "Date of judgment"},
            {"name": "docket_number", "dataType": ["text"], "description": "Case docket number"},
            {
                "name": "document_type",
                "dataType": ["text"],
                "description": "Type (wyrok, uchwaÅ‚a, postanowienie)",
            },
            {"name": "judges", "dataType": ["text[]"], "description": "Panel of judges"},
            {"name": "legal_bases", "dataType": ["text[]"], "description": "Legal articles cited"},
            {"name": "keywords", "dataType": ["text[]"], "description": "Legal keywords/topics"},
            {"name": "full_text", "dataType": ["text"], "description": "Complete judgment text"},
            {
                "name": "court_type",
                "dataType": ["text"],
                "description": "Court level (district/regional/supreme)",
            },
            {
                "name": "judgment_type",
                "dataType": ["text"],
                "description": "Judgment classification",
            },
            {"name": "country", "dataType": ["text"], "description": "Poland"},
            {"name": "language", "dataType": ["text"], "description": "pl"},
        ],
    }

    print("\nğŸ—ï¸  Creating enhanced Polish legal schema...")
    response = requests.post(f"{WEAVIATE_URL}/v1/schema", json=schema, headers=HEADERS)
    if response.status_code == 200:
        print("âœ… Enhanced schema created successfully")
    else:
        print(f"âŒ Schema creation failed: {response.text}")
        return

    print("\nğŸ“¥ Ingesting Polish court documents...")
    success_count = 0

    for doc in sample_polish_docs:
        response = requests.post(
            f"{WEAVIATE_URL}/v1/objects",
            json={"class": "PolishLegalDocument", "properties": doc},
            headers=HEADERS,
        )

        if response.status_code in [200, 201]:
            success_count += 1
            court_type = doc["court_type"].title()
            print(f"  âœ… {court_type} Court document ingested: {doc['document_id']}")
        else:
            print(f"  âŒ Failed: {doc['document_id']}")

    print(f"\nğŸ“Š Successfully ingested: {success_count}/{len(sample_polish_docs)} documents")

    # Demonstrate queries specific to Polish legal system
    print("\nğŸ” POLISH LEGAL SYSTEM QUERIES")
    print("-" * 50)

    queries = [
        ("odszkodowanie", "Compensation/damages cases"),
        ("konsument", "Consumer protection cases"),
        ("dobra osobiste", "Personal rights cases"),
        ("SÄ…d NajwyÅ¼szy", "Supreme Court cases"),
    ]

    for query, description in queries:
        print(f"\nğŸ” Searching: '{query}' ({description})")

        graphql_query = f"""
        {{
          Get {{
            PolishLegalDocument(
              where: {{
                operator: Or
                operands: [
                  {{
                    path: ["full_text"]
                    operator: Like
                    valueText: "*{query}*"
                  }}
                  {{
                    path: ["keywords"]
                    operator: Like
                    valueText: "*{query}*"
                  }}
                  {{
                    path: ["court_name"]
                    operator: Like
                    valueText: "*{query}*"
                  }}
                ]
              }}
              limit: 2
            ) {{
              document_id
              court_name
              court_type
              docket_number
              judgment_type
              keywords
            }}
          }}
        }}
        """

        response = requests.post(
            f"{WEAVIATE_URL}/v1/graphql", json={"query": graphql_query}, headers=HEADERS
        )

        if response.status_code == 200:
            data = response.json()
            documents = data.get("data", {}).get("Get", {}).get("PolishLegalDocument", [])

            if documents:
                for doc in documents:
                    print(f"  ğŸ“„ {doc['docket_number']} ({doc['court_type']} court)")
                    print(f"      Court: {doc['court_name']}")
                    print(f"      Type: {doc['judgment_type']}")
                    print(f"      Keywords: {', '.join(doc.get('keywords', [])[:3])}...")
            else:
                print("  âŒ No matches found")

    print("\n\nğŸ‰ LOCAL POLISH DATASET INGESTION COMPLETE!")
    print("-" * 60)
    print("This demonstrates ingestion from local parquet files containing:")
    print("âœ… Polish court judgments from all court levels")
    print("âœ… Rich legal metadata (judges, legal bases, keywords)")
    print("âœ… Full-text search across legal content")
    print("âœ… Court hierarchy representation")
    print("âœ… Polish legal terminology support")

    print("\nğŸš€ To ingest from actual parquet files:")
    print(
        "python scripts/dataset_manager.py ingest 'parquet:data/datasets/pl/raw/' --max-docs 1000"
    )


def show_local_files_available():
    """Show what local dataset files are available."""

    print("\nğŸ“‚ LOCAL DATASET FILES DETECTED")
    print("-" * 50)

    base_path = Path("/home/laugustyniak/github/legal-ai/JuDDGES/data/datasets")

    # Polish datasets
    pl_raw_path = base_path / "pl" / "raw"
    if pl_raw_path.exists():
        parquet_files = list(pl_raw_path.glob("*.parquet"))
        total_size = sum(f.stat().st_size for f in parquet_files) / (1024**3)  # GB
        print("ğŸ‡µğŸ‡± Polish Court Raw Data:")
        print(f"   ğŸ“ Location: {pl_raw_path}")
        print(f"   ğŸ“Š Files: {len(parquet_files)} parquet files")
        print(f"   ğŸ’¾ Size: {total_size:.1f} GB")
        print("   ğŸ“„ Estimated: 1,000,000+ documents")

    # English datasets
    en_path = base_path / "en"
    if en_path.exists():
        if (en_path / "csv" / "judgments.csv").exists():
            print("\nğŸ‡¬ğŸ‡§ English Court Data:")
            print(f"   ğŸ“ CSV: {en_path / 'csv' / 'judgments.csv'}")

        if (en_path / "en_judgements_dataset").exists():
            print(f"   ğŸ“ Arrow: {en_path / 'en_judgements_dataset'}")
            print("   ğŸ“„ Estimated: 500,000+ documents")

    # NSA datasets
    nsa_path = base_path / "nsa"
    if nsa_path.exists():
        print("\nâš–ï¸  NSA (Supreme Administrative Court):")
        print(f"   ğŸ“ Location: {nsa_path}")
        print("   ğŸ“„ Estimated: 50,000+ documents")

    print("\nğŸ’¡ Use any of these local datasets with:")
    print("   python scripts/dataset_manager.py preview 'local:path/to/dataset'")


if __name__ == "__main__":
    # Test Weaviate connection
    try:
        response = requests.get(f"{WEAVIATE_URL}/v1/meta", headers=HEADERS)
        if response.status_code != 200:
            print(
                "âŒ Weaviate not running. Start with: docker run -d --name weaviate-test -p 8084:8080 cr.weaviate.io/semitechnologies/weaviate:1.26.1"
            )
            exit(1)
    except Exception as e:
        print(f"âŒ Cannot connect to Weaviate: {e}")
        exit(1)

    ingest_local_polish_sample()
    show_local_files_available()
