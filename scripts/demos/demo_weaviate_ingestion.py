#!/usr/bin/env python3
"""
Demo script to show Weaviate ingestion with sample legal documents.
This demonstrates the key concepts without requiring full dependencies.
"""

from typing import Any, Dict, List

import requests

# Weaviate connection details
WEAVIATE_URL = "http://localhost:8084"
API_KEY = "PQA2.12-**lafqf"
HEADERS = {"Authorization": f"Bearer {API_KEY}"}


def create_legal_documents_schema():
    """Create schema for legal documents in Weaviate."""

    schema = {
        "class": "LegalDocument",
        "description": "Legal documents from courts",
        "properties": [
            {
                "name": "document_id",
                "dataType": ["text"],
                "description": "Unique document identifier",
            },
            {"name": "court_name", "dataType": ["text"], "description": "Name of the court"},
            {
                "name": "judgment_date",
                "dataType": ["date"],
                "description": "Date when judgment was issued",
            },
            {
                "name": "document_type",
                "dataType": ["text"],
                "description": "Type of legal document",
            },
            {
                "name": "full_text",
                "dataType": ["text"],
                "description": "Full text content of the document",
            },
            {"name": "judges", "dataType": ["text[]"], "description": "List of judges involved"},
            {
                "name": "legal_bases",
                "dataType": ["text[]"],
                "description": "Legal bases referenced",
            },
            {"name": "keywords", "dataType": ["text[]"], "description": "Document keywords/tags"},
            {"name": "country", "dataType": ["text"], "description": "Country/jurisdiction"},
            {"name": "language", "dataType": ["text"], "description": "Document language"},
        ],
    }

    response = requests.post(f"{WEAVIATE_URL}/v1/schema", json=schema, headers=HEADERS)
    if response.status_code == 200:
        print("âœ… Legal documents schema created successfully")
    else:
        print(f"âŒ Schema creation failed: {response.status_code} - {response.text}")

    return response.status_code == 200


def create_document_chunks_schema():
    """Create schema for document chunks in Weaviate."""

    schema = {
        "class": "DocumentChunk",
        "description": "Text chunks from legal documents for vector search",
        "properties": [
            {
                "name": "document_id",
                "dataType": ["text"],
                "description": "Parent document identifier",
            },
            {"name": "chunk_id", "dataType": ["text"], "description": "Unique chunk identifier"},
            {
                "name": "chunk_text",
                "dataType": ["text"],
                "description": "Text content of the chunk",
            },
            {
                "name": "position",
                "dataType": ["int"],
                "description": "Position of chunk in document",
            },
            {
                "name": "chunk_length",
                "dataType": ["int"],
                "description": "Length of chunk in characters",
            },
            {
                "name": "court_name",
                "dataType": ["text"],
                "description": "Court name from parent document",
            },
            {
                "name": "judgment_date",
                "dataType": ["date"],
                "description": "Judgment date from parent document",
            },
        ],
    }

    response = requests.post(f"{WEAVIATE_URL}/v1/schema", json=schema, headers=HEADERS)
    if response.status_code == 200:
        print("âœ… Document chunks schema created successfully")
    else:
        print(f"âŒ Schema creation failed: {response.status_code} - {response.text}")

    return response.status_code == 200


def create_sample_legal_documents() -> List[Dict[str, Any]]:
    """Create sample legal documents similar to JuDDGES/pl-court-raw format."""

    documents = [
        {
            "document_id": "PL_SCO_2023_001",
            "court_name": "SÄ…d NajwyÅ¼szy",
            "judgment_date": "2023-03-15T00:00:00Z",
            "document_type": "judgment",
            "full_text": """WYROK z dnia 15 marca 2023 r.

SÄ„DU NAJWYÅ»SZEGO
Izba Cywilna

W sprawie z powÃ³dztwa obywatela o zapÅ‚atÄ™ odszkodowania za szkody wyrzÄ…dzone przez nieprawidÅ‚owe dziaÅ‚anie urzÄ™du.

UZASADNIENIE:
SÄ…d uznaÅ‚ za zasadne Å¼Ä…danie powoda dotyczÄ…ce odszkodowania. Przepisy kodeksu cywilnego w art. 417 jasno okreÅ›lajÄ… odpowiedzialnoÅ›Ä‡ Skarbu PaÅ„stwa za szkody wyrzÄ…dzone przez funkcjonariuszy publicznych przy wykonywaniu ich obowiÄ…zkÃ³w.

W przedmiotowej sprawie udowodniono, Å¼e dziaÅ‚ania urzÄ™dnikÃ³w byÅ‚y sprzeczne z prawem i spowodowaÅ‚y konkretne straty materialne po stronie powoda.""",
            "judges": ["Jan Kowalski", "Anna Nowak", "Piotr WiÅ›niewski"],
            "legal_bases": [
                "art. 417 k.c.",
                "art. 471 k.c.",
                "ustawa o postÄ™powaniu administracyjnym",
            ],
            "keywords": ["odszkodowanie", "odpowiedzialnoÅ›Ä‡", "Skarb PaÅ„stwa", "szkoda"],
            "country": "Poland",
            "language": "pl",
        },
        {
            "document_id": "PL_ACO_2023_456",
            "court_name": "WojewÃ³dzki SÄ…d Administracyjny w Warszawie",
            "judgment_date": "2023-04-22T00:00:00Z",
            "document_type": "judgment",
            "full_text": """WYROK z dnia 22 kwietnia 2023 r.

WOJEWÃ“DZKIEGO SÄ„DU ADMINISTRACYJNEGO W WARSZAWIE

W sprawie odwoÅ‚ania od decyzji administracyjnej dotyczÄ…cej odmowy wydania pozwolenia na budowÄ™.

UZASADNIENIE:
SÄ…d po rozpoznaniu sprawy uznaÅ‚ odwoÅ‚anie za uzasadnione. Organ administracji publicznej bÅ‚Ä™dnie zinterpretowaÅ‚ przepisy prawa budowlanego, w szczegÃ³lnoÅ›ci art. 35 ust. 1 ustawy Prawo budowlane.

Decyzja organu pierwszej instancji zostaÅ‚a uchylona z uwagi na naruszenie prawa materialnego. Sprawa zostaje przekazana do ponownego rozpoznania.""",
            "judges": ["Maria Kowalczyk"],
            "legal_bases": [
                "art. 35 ust. 1 Prawa budowlanego",
                "ustawa o postÄ™powaniu administracyjnym",
            ],
            "keywords": [
                "pozwolenie na budowÄ™",
                "prawo budowlane",
                "odwoÅ‚anie",
                "uchylenie decyzji",
            ],
            "country": "Poland",
            "language": "pl",
        },
        {
            "document_id": "PL_DCO_2023_789",
            "court_name": "SÄ…d Rejonowy w Krakowie",
            "judgment_date": "2023-05-10T00:00:00Z",
            "document_type": "judgment",
            "full_text": """WYROK z dnia 10 maja 2023 r.

SÄ„DU REJONOWEGO W KRAKOWIE
WydziaÅ‚ Cywilny

W sprawie o zapÅ‚atÄ™ wynagrodzenia za wykonane usÅ‚ugi prawnicze.

UZASADNIENIE:
SÄ…d przychyliÅ‚ siÄ™ do Å¼Ä…daÅ„ powoda w peÅ‚nej wysokoÅ›ci. Umowa o Å›wiadczenie usÅ‚ug prawniczych zostaÅ‚a zawarta w sposÃ³b waÅ¼ny i strony byÅ‚y zwiÄ…zane jej postanowieniami.

Pozwany nie wykazaÅ‚ Å¼adnych okolicznoÅ›ci, ktÃ³re mogÅ‚yby uzasadniaÄ‡ odmowÄ™ zapÅ‚aty wynagrodzenia. PowÃ³d udowodniÅ‚ wykonanie wszystkich usÅ‚ug zgodnie z umowÄ….""",
            "judges": ["Tomasz Nowacki", "Agnieszka Kowalska"],
            "legal_bases": ["art. 750 k.c.", "art. 627 k.c."],
            "keywords": ["wynagrodzenie", "usÅ‚ugi prawnicze", "umowa", "zapÅ‚ata"],
            "country": "Poland",
            "language": "pl",
        },
    ]

    return documents


def create_document_chunks(documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Create text chunks from documents for vector search."""

    chunks = []

    for doc in documents:
        full_text = doc["full_text"]

        # Simple chunking by paragraphs
        paragraphs = [p.strip() for p in full_text.split("\n\n") if p.strip()]

        for i, paragraph in enumerate(paragraphs):
            if len(paragraph) > 50:  # Only meaningful chunks
                chunk = {
                    "document_id": doc["document_id"],
                    "chunk_id": f"{doc['document_id']}_chunk_{i:03d}",
                    "chunk_text": paragraph,
                    "position": i,
                    "chunk_length": len(paragraph),
                    "court_name": doc["court_name"],
                    "judgment_date": doc["judgment_date"],
                }
                chunks.append(chunk)

    return chunks


def ingest_documents(documents: List[Dict[str, Any]]) -> bool:
    """Ingest documents into Weaviate."""

    print(f"\nğŸ“¥ Ingesting {len(documents)} legal documents...")

    success_count = 0
    for doc in documents:
        response = requests.post(
            f"{WEAVIATE_URL}/v1/objects", json={"class": "LegalDocument", "properties": doc}, headers=HEADERS
        )

        if response.status_code in [200, 201]:
            success_count += 1
            print(f"  âœ… Document {doc['document_id']} ingested successfully")
        else:
            print(f"  âŒ Failed to ingest {doc['document_id']}: {response.text}")

    print(f"\nğŸ“Š Documents ingested: {success_count}/{len(documents)}")
    return success_count == len(documents)


def ingest_chunks(chunks: List[Dict[str, Any]]) -> bool:
    """Ingest document chunks into Weaviate."""

    print(f"\nğŸ“¥ Ingesting {len(chunks)} document chunks...")

    success_count = 0
    for chunk in chunks:
        response = requests.post(
            f"{WEAVIATE_URL}/v1/objects", json={"class": "DocumentChunk", "properties": chunk}, headers=HEADERS
        )

        if response.status_code in [200, 201]:
            success_count += 1
        else:
            print(f"  âŒ Failed to ingest chunk {chunk['chunk_id']}: {response.text}")

    print(f"ğŸ“Š Chunks ingested: {success_count}/{len(chunks)}")
    return success_count == len(chunks)


def query_documents(query: str, limit: int = 3):
    """Query documents using keyword search."""

    print(f"\nğŸ” Searching for: '{query}'")

    graphql_query = f"""
    {{
      Get {{
        LegalDocument(
          where: {{
            operator: Or
            operands: [
              {{
                path: ["full_text"]
                operator: Like
                valueText: "*{query}*"
              }}
              {{
                path: ["keywords"]
                operator: Like  
                valueText: "*{query}*"
              }}
            ]
          }}
          limit: {limit}
        ) {{
          document_id
          court_name
          judgment_date
          keywords
          full_text
        }}
      }}
    }}
    """

    response = requests.post(f"{WEAVIATE_URL}/v1/graphql", json={"query": graphql_query}, headers=HEADERS)

    if response.status_code == 200:
        data = response.json()
        documents = data.get("data", {}).get("Get", {}).get("LegalDocument", [])

        if documents:
            print(f"ğŸ“‹ Found {len(documents)} matching documents:")
            for i, doc in enumerate(documents, 1):
                print(f"\n{i}. Document: {doc['document_id']}")
                print(f"   Court: {doc['court_name']}")
                print(f"   Date: {doc['judgment_date'][:10]}")
                print(f"   Keywords: {', '.join(doc.get('keywords', []))}")
                print(f"   Text preview: {doc['full_text'][:200]}...")
        else:
            print("âŒ No documents found matching the query")
    else:
        print(f"âŒ Query failed: {response.status_code} - {response.text}")


def show_statistics():
    """Show collection statistics."""

    print("\nğŸ“Š WEAVIATE COLLECTION STATISTICS")
    print("=" * 50)

    # Count documents
    doc_query = """
    {
      Aggregate {
        LegalDocument {
          meta {
            count
          }
        }
      }
    }
    """

    response = requests.post(f"{WEAVIATE_URL}/v1/graphql", json={"query": doc_query}, headers=HEADERS)
    if response.status_code == 200:
        data = response.json()
        doc_count = (
            data.get("data", {})
            .get("Aggregate", {})
            .get("LegalDocument", [{}])[0]
            .get("meta", {})
            .get("count", 0)
        )
        print(f"ğŸ“„ Legal Documents: {doc_count}")

    # Count chunks
    chunk_query = """
    {
      Aggregate {
        DocumentChunk {
          meta {
            count
          }
        }
      }
    }
    """

    response = requests.post(f"{WEAVIATE_URL}/v1/graphql", json={"query": chunk_query}, headers=HEADERS)
    if response.status_code == 200:
        data = response.json()
        chunk_count = (
            data.get("data", {})
            .get("Aggregate", {})
            .get("DocumentChunk", [{}])[0]
            .get("meta", {})
            .get("count", 0)
        )
        print(f"ğŸ“ Document Chunks: {chunk_count}")


def main():
    """Main demo function."""

    print("ğŸ›ï¸  WEAVIATE LEGAL DOCUMENTS INGESTION DEMO")
    print("=" * 60)
    print()
    print("This demo shows how the Universal Ingestion System")
    print("would work with Polish court documents (JuDDGES/pl-court-raw)")
    print()

    # Test connection
    try:
        response = requests.get(f"{WEAVIATE_URL}/v1/meta", headers=HEADERS)
        if response.status_code != 200:
            print("âŒ Cannot connect to Weaviate")
            return
        print("âœ… Connected to Weaviate successfully")
    except Exception as e:
        print(f"âŒ Connection failed: {e}")
        return

    # Create schemas
    print("\nğŸ—ï¸  Creating schemas...")
    if not create_legal_documents_schema():
        return
    if not create_document_chunks_schema():
        return

    # Create sample data
    print("\nğŸ“ Creating sample data...")
    documents = create_sample_legal_documents()
    chunks = create_document_chunks(documents)

    print(f"ğŸ“„ Created {len(documents)} sample documents")
    print(f"ğŸ“ Created {len(chunks)} text chunks")

    # Ingest data
    if not ingest_documents(documents):
        print("âŒ Document ingestion failed")
        return

    if not ingest_chunks(chunks):
        print("âŒ Chunk ingestion failed")
        return

    # Show statistics
    show_statistics()

    # Demo queries
    print("\nğŸ” DEMONSTRATION QUERIES")
    print("=" * 50)

    query_documents("odszkodowanie")
    query_documents("prawo budowlane")
    query_documents("wynagrodzenie")

    print("\nğŸ‰ DEMO COMPLETED SUCCESSFULLY!")
    print("\nKey features demonstrated:")
    print("âœ… Automatic schema creation for Polish legal documents")
    print("âœ… Document and chunk ingestion")
    print("âœ… Text search across legal content")
    print("âœ… Metadata handling (judges, legal bases, keywords)")
    print("âœ… Multi-court document support")
    print("\nThis represents what would happen with JuDDGES/pl-court-raw:")
    print("â€¢ 1000+ documents from various Polish courts")
    print("â€¢ Automatic field mapping (judgment_id â†’ document_id, etc.)")
    print("â€¢ Intelligent text chunking for vector search")
    print("â€¢ Rich metadata preservation")


if __name__ == "__main__":
    main()
