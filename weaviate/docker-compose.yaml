name: legal_ai

services:
  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.30.2
    depends_on:
      - t2v-transformers
    ports:
      - 8084:8080
      - 50051:50051
    volumes:
      - legal_ai_weaviate_prod:/var/lib/weaviate
    env_file: .env
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
      resources:
        limits:
          cpus: '25'
          memory: '60G'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  t2v-transformers:
    build:
      context: .
      dockerfile: hf_transformers.dockerfile
      args:
        MODEL_NAME: ${MODEL_NAME}
        ENABLE_CUDA: ${ENABLE_CUDA}
    env_file:
      - .env
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
      resources:
        limits:
          cpus: '8'
          memory: '16G'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  legal_ai_weaviate_prod:
    external: true
