{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "import datasets\n",
    "import transformers\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(\"notebook\")\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()\n",
    "datasets.utils.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "ds = load_dataset(\"JuDDGES/pl-court-instruct\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb2d131ba5aeb",
   "metadata": {},
   "source": [
    "# Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)\n",
    "\n",
    "## Table of Contents\n",
    "- [Table of Contents](#table-of-contents)\n",
    "- [Dataset Description](#dataset-description)\n",
    "  - [Dataset Summary](#dataset-summary)\n",
    "  - [Supported Tasks and Leaderboards](#supported-tasks-and-leaderboards)\n",
    "  - [Languages](#languages)\n",
    "- [Dataset Structure](#dataset-structure)\n",
    "  - [Data Instances](#data-instances)\n",
    "  - [Data Fields](#data-fields)\n",
    "  - [Data Splits](#data-splits)\n",
    "- [Dataset Creation](#dataset-creation)\n",
    "  - [Curation Rationale](#curation-rationale)\n",
    "  - [Source Data](#source-data)\n",
    "  - [Annotations](#annotations)\n",
    "  - [Personal and Sensitive Information](#personal-and-sensitive-information)\n",
    "- [Considerations for Using the Data](#considerations-for-using-the-data)\n",
    "  - [Social Impact of Dataset](#social-impact-of-dataset)\n",
    "  - [Discussion of Biases](#discussion-of-biases)\n",
    "  - [Other Known Limitations](#other-known-limitations)\n",
    "- [Additional Information](#additional-information)\n",
    "  - [Dataset Curators](#dataset-curators)\n",
    "  - [Licensing Information](#licensing-information)\n",
    "  - [Citation Information](#citation-information)\n",
    "  - [Contributions](#contributions)\n",
    "- [Statistics](#statistics)\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "* **Homepage: TBA**\n",
    "* **Repository: [github](https://github.com/pwr-ai/JuDDGES)**\n",
    "* **Paper:  TBA**\n",
    "* **Point of Contact: lukasz.augustyniak@pwr.edu.pl; jakub.binkowski@pwr.edu.pl; albert.sawczyn@pwr.edu.pl**\n",
    "\n",
    "### Dataset Summary\n",
    "\n",
    "The dataset consists of Polish Court judgements available at https://orzeczenia.ms.gov.pl/, containing full content of the judgements along with metadata sourced from official API and extracted from the judgement contents. This dataset is designed for fine-tuning large language models (LLMs) for information extraction tasks and is formatted as instructions. For raw dataset see [`JuDDGES/pl-court-raw`](https://huggingface.co/datasets/JuDDGES/pl-court-raw). For graph dataset see [`JuDDGES/pl-court-graph`](https://huggingface.co/datasets/JuDDGES/pl-court-graph).\n",
    "\n",
    "### Supported Tasks and Leaderboards\n",
    "\n",
    "* `information-extraction`: The dataset can be used for information extraction tasks.\n",
    "* `text-generation`: The dataset can be used for text generation tasks, as the dataset is formatted as instructions.\n",
    "\n",
    "### Languages\n",
    "\n",
    "pl-PL Polish \n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "### Data Instances\n",
    "\n",
    "<details>\n",
    "<summary> Click to expand </summary>\n",
    "\n",
    "```json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f161970acf83cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "display(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7071df5232016",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    " \n",
    "</details>\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "\n",
    "| Feature name     | Feature description                                                                                                                       | Type       |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------|------------|\n",
    "| _id              | Unique identifier of the judgement                                                                                                        | `string`   |\n",
    "| prompt           | The prompt template provided for extracting information from the judgement. It contains placeholder `{context}` for the judgement content. | `string`   |\n",
    "| context          | The full text content of the judgement                                                                                                    | `string`   |\n",
    "| output           | The extracted information in YAML format based on the provided context                                                                    | `string`   |\n",
    "\n",
    "\n",
    "### Data Splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96bab3205ad17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "data = []\n",
    "for split in ds.keys():\n",
    "    data.append({\"split\": split, \"# samples\": len(ds[split])})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"% samples\"] = (df[\"# samples\"] / df[\"# samples\"].sum() * 100).round(2)\n",
    "# print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee99a119109fc75",
   "metadata": {},
   "source": [
    "| split   |   # samples |   % samples |\n",
    "|:--------|------------:|------------:|\n",
    "| train   |      238851 |       99.17 |\n",
    "| test    |        2000 |        0.83 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a616415592b60",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Dataset Creation\n",
    "\n",
    "For details on the dataset creation, see the paper [TBA]() and the code repository [here](https://github.com/pwr-ai/JuDDGES).\n",
    "\n",
    "### Curation Rationale\n",
    "\n",
    "Created to enable cross-jurisdictional legal analytics.\n",
    "\n",
    "### Source Data\n",
    "\n",
    "#### Initial Data Collection and Normalization\n",
    "\n",
    "1. Utilize the raw dataset [`JuDDGES/pl-court-raw`](https://huggingface.co/datasets/JuDDGES/pl-court-raw).\n",
    "1. First, we identified information from metadata which is contained in text of the judgement. Therefore, the following fields were selected for extraction as targets:\n",
    "    * `date`\n",
    "    * `judges`\n",
    "    * `recorder`\n",
    "    * `signature`\n",
    "    * `court_name`\n",
    "    * `department_name`\n",
    "    * `legal_bases`\n",
    "1. **Data filtering**: In order to ensure high quality of the dataset, we performed filtering procedure, as described below.\n",
    "    1. Removal of judgements with missing values in targets - if any of the target field has missing value, entire judgement is discarded (information might still be contained in judgement text, and in such case the targets would be incorrect)\n",
    "    1. Cleaning `judges` field - in some examples, names of judges were concatenated into single name instead of being list of names, so we split them based on conjunction\n",
    "    1. Removing examples wherein targets are not in text - due to inherent errors in acquired data, some targets might be mistyped, hence we filter them out\n",
    "(Data cleaning removes 173297 examples, and dataset consists of 240851.)\n",
    "1. **Generating instructions**: After cleaning we generate instructions for information extraction. Specifically, we define same prompt for each document, as follows:\n",
    "\n",
    "    ```text\n",
    "    You are extracting information from the Polish court judgments.\n",
    "    Extract specified values strictly from the provided judgement. If information is not provided in the judgement, leave the field with null value.\n",
    "    Please return the response in the identical YAML format:\n",
    "    '''yaml\n",
    "    court_name: \"<nazwa sądu, string containing the full name of the court>\"\n",
    "    date: <data, date in format YYYY-MM-DD>\n",
    "    department_name: \"<nazwa wydziału, string containing the full name of the court's department>\"\n",
    "    judges: \"<sędziowie, list of judge full names>\"\n",
    "    legal_bases: <podstawy prawne, list of strings containing legal bases (legal regulations)>\n",
    "    recorder: <protokolant, string containing the name of the recorder>\n",
    "    signature: <sygnatura, string contraining the signature of the judgment>\n",
    "    '''\n",
    "    =====\n",
    "    {context}\n",
    "    ======\n",
    "    ```\n",
    "    where `{context}` is replaced by text of each judgement. We highlight that judgements are in Polish, hence to foster model responding in Polish, we provide name Polish names of the field in the prompt.\n",
    "\n",
    "\n",
    "#### Who are the source language producers?\n",
    "\n",
    "Produced by human legal professionals (judges, court clerks). Demographics was not analysed. Sourced from public court databases.\n",
    "\n",
    "### Annotations\n",
    "\n",
    "#### Annotation process\n",
    "\n",
    "No annotation was performed by us. All features were provided via API.\n",
    "\n",
    "#### Who are the annotators?\n",
    "\n",
    "As above.\n",
    "\n",
    "### Personal and Sensitive Information\n",
    "\n",
    "Pseudoanonymized to comply with GDPR (art. 4 sec. 5 GDPR).\n",
    "\n",
    "## Considerations for Using the Data\n",
    "\n",
    "### Social Impact of Dataset\n",
    "\n",
    "[More Information Needed]\n",
    "\n",
    "### Discussion of Biases\n",
    "\n",
    "[More Information Needed]\n",
    "\n",
    "### Other Known Limitations\n",
    "\n",
    "[More Information Needed]\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "### Dataset Curators\n",
    "\n",
    "[More Information Needed]\n",
    "\n",
    "### Licensing Information\n",
    "\n",
    "[More Information Needed]\n",
    "\n",
    "### Citation Information\n",
    "\n",
    "[More Information Needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74927a24aba40b",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1df108f7be20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "data = yaml.safe_load(ds[\"train\"][\"output\"][0].replace(\"```yaml\", \"\").replace(\"```\", \"\"))\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a063bc04e4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def parse_output(output: str) -> dict:\n",
    "    data = yaml.safe_load(output.replace(\"```yaml\", \"\").replace(\"```\", \"\"))\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    return data\n",
    "\n",
    "ds = ds.map(parse_output, input_columns=\"output\", num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31a01d116567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "pl_ds = pl.concat([pl.from_arrow(ds[\"train\"].data.table), pl.from_arrow(ds[\"test\"].data.table)])\n",
    "pl_ds = pl_ds.with_columns(pl.Series(name=\"subset\", values=[\"train\"] * len(ds[\"train\"]) + [\"test\"] * len(ds[\"test\"]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "court_distribution = pl_ds.select([\"subset\", \"court_name\"]).group_by([\"subset\", \"court_name\"]).len().sort(\"len\", descending=True).to_pandas()\n",
    "ax = sns.histplot(data=court_distribution, x=\"len\", hue=\"subset\", log_scale=True, kde=True, stat=\"percent\", common_norm=False )\n",
    "ax.set(title=\"Distribution of judgments per court\", xlabel=\"#Judgements in single court\", ylabel=\"percent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201a1725cbbca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "judgements_per_year = pl_ds.select([\"subset\", \"date\"])[[\"subset\", \"date\"]]\n",
    "judgements_per_year = judgements_per_year.with_columns(judgements_per_year[\"date\"].dt.year()) \n",
    "judgements_per_year = judgements_per_year.group_by([\"subset\", \"date\"]).len().sort(\"date\")\n",
    "judgements_per_year = judgements_per_year.to_pandas()\n",
    "judgements_per_year[\"%\"] = judgements_per_year.groupby(\"subset\")[\"len\"].transform(lambda x: x / x.sum() * 100) \n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax = sns.pointplot(data=judgements_per_year, x=\"date\", y=\"%\", hue=\"subset\", linestyles=\"--\", ax=ax)\n",
    "ax.set(xlabel=\"Year\", ylabel=\"% Judgements\", title=\"Yearly Number of Judgements\", yscale=\"log\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0801346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "num_judges = pl_ds.with_columns([pl.col(\"judges\").list.len().alias(\"num_judges\")]).select([\"subset\", \"num_judges\"]).to_pandas()\n",
    "ax = sns.histplot(data=num_judges, x=\"num_judges\", hue=\"subset\", bins=num_judges[\"num_judges\"].nunique(), stat=\"percent\", common_norm=False)\n",
    "ax.set(xlabel=\"#Judges per judgement\", ylabel=\"%\", title=\"#Judges per single judgement\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030652c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "def tokenize(batch: dict[str, list]) -> list[int]: \n",
    "    tokenized = tokenizer(batch[\"context\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n",
    "    return {\"length\": tokenized[\"length\"]}\n",
    "\n",
    "ds = ds.map(tokenize, batched=True, batch_size=16, remove_columns=[\"context\"], num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f46bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "context_len_train = ds[\"train\"].to_pandas()\n",
    "context_len_train[\"subset\"] = \"train\"\n",
    "context_len_test = ds[\"test\"].to_pandas()\n",
    "context_len_test[\"subset\"] = \"test\"\n",
    "context_len = pd.concat([context_len_train, context_len_test])\n",
    "\n",
    "ax = sns.histplot(data=context_len, x=\"length\", bins=50, hue=\"subset\")\n",
    "ax.set(xlabel=\"#Tokens\", ylabel=\"Count\", title=\"#Tokens distribution in context (llama-3 tokenizer)\", yscale=\"log\")\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x/1_000)}k'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
