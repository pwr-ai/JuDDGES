vars:
  - seeds: [42, 7312, 997]

stages:
  raw_dataset_readme:
    cmd: >-
      jupyter nbconvert
      --no-input
      --to markdown
      --execute 'nbs/Dataset Cards/01_Dataset_Description_Raw.ipynb'
      --output-dir data/datasets/pl/pl-court-raw
      --output README
    deps:
      - nbs/Dataset Cards/01_Dataset_Description_Raw.ipynb
      - data/datasets/pl/pl-court-raw/data/
    outs:
      - data/datasets/pl/pl-court-raw/README.md
      - data/datasets/pl/pl-court-raw/README_files/

  embed:
    matrix:
      model:
        - mmlw-roberta-large
      dataset:
        - pl-court-raw
        - en-court-raw
        - pl-nsa
    cmd: >-
      PYTHONPATH=. python scripts/embed/embed_text.py
      embedding_model=${item.model}
      dataset_name=JuDDGES/${item.dataset}
      output_dir=data/embeddings/${item.dataset}/${item.model}
    deps:
      - scripts/embed/embed_text.py
      - configs/embedding.yaml
      - configs/embedding_model/${item.model}.yaml
    outs:
      - data/embeddings/${item.dataset}/${item.model}/chunk_embeddings
      - data/embeddings/${item.dataset}/${item.model}/agg_embeddings

  build_graph_dataset:
    cmd: >-
      PYTHONPATH=. python scripts/dataset/build_graph_dataset.py
      --dataset-dir data/datasets/pl/raw
      --embeddings-root-dir data/embeddings/pl-court-raw/mmlw-roberta-large/
      --target-dir data/datasets/pl/graph
    deps:
      - scripts/dataset/build_graph_dataset.py
      - juddges/data/pl_court_graph.py
      - data/datasets/pl/raw
      - data/embeddings/pl-court-raw/mmlw-roberta-large/agg_embeddings.pt
      - data/embeddings/pl-court-raw/mmlw-roberta-large/all_embeddings/config.yaml
    outs:
      - data/datasets/pl/graph/data
      - data/datasets/pl/graph/metadata.yaml

  build_swiss_franc_loans_instruct_dataset:
    cmd: >-
      PYTHONPATH=. python scripts/dataset/build_swiss_franc_loans_instruct_dataset.py
      --dataset-source-path data/datasets/pl/swiss_franc_loans_source/
      --output-dir data/datasets/pl/swiss_franc_loans
      --tokenizer-name meta-llama/Llama-3.1-8B-Instruct
      --schema-path configs/ie_schema/swiss_franc_loans.yaml
      --threshold-tokens 64_000
    deps:
      - scripts/dataset/build_swiss_franc_loans_instruct_dataset.py
      - configs/ie_schema/swiss_franc_loans.yaml
      - data/datasets/pl/swiss_franc_loans_source/
    outs:
      - data/datasets/pl/swiss_franc_loans/train.json
      - data/datasets/pl/swiss_franc_loans/test.json
      - data/datasets/pl/swiss_franc_loans/annotated.json
      - data/datasets/pl/swiss_franc_loans/dataset_info.json

  build_en_appealcourt_coded_dataset:
    cmd: >-
      PYTHONPATH=. python scripts/dataset/build_en_appealcourt_coded_dataset.py
      --target-dir data/datasets/en/en_appealcourt_coded
      --schema-file configs/ie_schema/en_appealcourt.yaml
    deps:
      - scripts/dataset/build_en_appealcourt_coded_dataset.py
      - configs/ie_schema/en_appealcourt.yaml
      - data/datasets/en/en_appealcourt_coded_source/
    outs:
      - data/datasets/en/en_appealcourt_coded/train.json
      - data/datasets/en/en_appealcourt_coded/test.json
      - data/datasets/en/en_appealcourt_coded/annotated.json
      - data/datasets/en/en_appealcourt_coded/dataset_info.json

  ### ---------------------------- Fine-tuning ---------------------------- ###
  sft:
    matrix: &sft_models
      llm_dataset:
        - dataset: pl_court_swiss_franc_loans
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: llama_3.2_3b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: mistral_nemo_instruct_2407
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: pllum_12b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: bielik_11b_v23_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
    cmd: >-
      PYTHONPATH=. python scripts/sft/fine_tune_deepspeed.py
      dataset=${item.llm_dataset.dataset}
      llm=${item.llm_dataset.llm}
      prompt=${item.llm_dataset.prompt}
      ie_schema=${item.llm_dataset.ie_schema}
    deps:
      - scripts/sft/fine_tune_deepspeed.py
      - configs/peft_fine_tuning.yaml
      - configs/llm/${item.llm_dataset.llm}.yaml
    outs:
      - data/experiments/peft-fine-tune/${item.llm_dataset.llm}/${item.llm_dataset.dataset}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/

  ### ---------------------------- Evaluate with human annotations ---------------------------- ###
  convert_splits_to_predcictions:
    matrix:
      datasets_outputs:
        - dataset: data/datasets/pl/swiss_franc_loans
          output_dir: data/experiments/predict/raw/pl_court_swiss_franc_loans/test/gpt_4.1/
        - dataset: data/datasets/en/en_appealcourt_coded
          output_dir: data/experiments/predict/raw/en_appealcourt_coded/test/gpt_4.1/
    cmd: >-
      PYTHONPATH=. python scripts/dataset/convert_splits_to_eval_data.py
      --dataset-name-or-path ${item.datasets_outputs.dataset}
      --output-dir ${item.datasets_outputs.output_dir}
    deps:
      - scripts/dataset/convert_splits_to_eval_data.py
      - ${item.datasets_outputs.dataset}
    outs:
      - ${item.datasets_outputs.output_dir}/predictions.json

  ### ---------------------------- Prediction ---------------------------- ###
  predict_raw_vllm:
    matrix: &predict_raw_vllm_matrix
      llm_dataset:
        # 0
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        # 1
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: llama_3.2_3b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        # 2
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: mistral_nemo_instruct_2407
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        # 3
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: pllum_12b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        # 4
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: bielik_11b_v23_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        ### NEW PROMPT ###
        # 5
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_annotated_json_refined
          ie_schema: swiss_franc_loans_refined
        # 6
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: qwen_3_8b
          prompt: info_extraction_annotated_json_refined
          ie_schema: swiss_franc_loans_refined
        # 7
        - dataset: pl_court_swiss_franc_loans
          split: annotated
          llm: qwen_3_32b
          prompt: info_extraction_annotated_json_refined
          ie_schema: swiss_franc_loans_refined
        ### PERSONAL RIGHTS DATASET ###
        # 8
        - dataset: pl_court_personal_rights
          split: train
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: personal_rights
        # 9
        - dataset: pl_court_personal_rights
          split: train
          llm: qwen_3_8b
          prompt: info_extraction_annotated_json
          ie_schema: personal_rights
        # 10
        - dataset: pl_court_personal_rights
          split: train
          llm: qwen_3_8b
          prompt: info_extraction_annotated_json_refined
          ie_schema: personal_rights
        # 11
        - dataset: pl_court_personal_rights
          split: train
          llm: qwen_3_8b
          prompt: info_extraction_json
          ie_schema: personal_rights
        # 12
        - dataset: pl_court_personal_rights
          split: train
          llm: qwen_3_32b
          prompt: info_extraction_annotated_json_refined
          ie_schema: personal_rights
        ### ENGLISH DATASET ###
        # 13
        - dataset: en_appealcourt_coded
          split: annotated
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_json
          ie_schema: en_appealcourt
        # 14
        - dataset: en_appealcourt_coded
          split: annotated
          llm: llama_3.2_3b_instruct
          prompt: info_extraction_json
          ie_schema: en_appealcourt
        # 15
        - dataset: en_appealcourt_coded
          split: annotated
          llm: mistral_nemo_instruct_2407
          prompt: info_extraction_json
          ie_schema: en_appealcourt
      seed: ${seeds}
    cmd: >-
      PYTHONPATH=. python scripts/sft/predict_vllm.py
      dataset=${item.llm_dataset.dataset}
      llm=${item.llm_dataset.llm}
      prompt=${item.llm_dataset.prompt}
      ie_schema=${item.llm_dataset.ie_schema}
      random_seed=${item.seed}
      split=${item.llm_dataset.split}
      output_dir=data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
    deps:
      - scripts/sft/predict_vllm.py
      - configs/predict.yaml
      - configs/llm/${item.llm_dataset.llm}.yaml
      - configs/prompt/${item.llm_dataset.prompt}.yaml
      - configs/ie_schema/${item.llm_dataset.ie_schema}.yaml
    outs:
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/predictions.json
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/dataset.json
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/config.yaml

  predict_swiss_franc_loans_on_fine_tuned_vllm:
    matrix:
      <<: *sft_models
      seed: ${seeds}
      split:
        - annotated
    cmd: >-
      PYTHONPATH=. python scripts/sft/predict_vllm.py
      dataset=${item.llm_dataset.dataset}
      llm=${item.llm_dataset.llm}
      prompt=${item.llm_dataset.prompt}
      ie_schema=${item.llm_dataset.ie_schema}
      random_seed=${item.seed}
      split=${item.split}
      llm.adapter_path=data/experiments/peft-fine-tune/${item.llm_dataset.llm}/${item.llm_dataset.dataset}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/
      output_dir=data/experiments/predict/fine_tuned_vllm/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
    deps:
      - scripts/sft/predict_vllm.py
      - configs/predict.yaml
      - configs/llm/${item.llm_dataset.llm}.yaml
      - configs/prompt/${item.llm_dataset.prompt}.yaml
      - configs/ie_schema/${item.llm_dataset.ie_schema}.yaml
      - data/experiments/peft-fine-tune/${item.llm_dataset.llm}/${item.llm_dataset.dataset}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/
    outs:
      - data/experiments/predict/fine_tuned_vllm/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/predictions.json
      - data/experiments/predict/fine_tuned_vllm/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/dataset.json
      - data/experiments/predict/fine_tuned_vllm/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/config.yaml

  ### ---------------------------- Evaluation ---------------------------- ###
  evaluate_ngram_based:
    matrix:
      <<: *predict_raw_vllm_matrix
    cmd: >-
      PYTHONPATH=. python scripts/evaluation/ngram_based_eval.py
      data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
    deps:
      - scripts/evaluation/ngram_based_eval.py
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
    outs:
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/scores_ngram.json

  # NOTE: This stage depends on the unbatched evaluation. To reduce costs, use batch script and commit the results.
  evaluate_llm_as_judge:
    matrix:
      <<: *predict_raw_vllm_matrix
      judge_llm:
        - gpt-4.1-mini-2025-04-14
    cmd: >-
      PYTHONPATH=. python scripts/evaluation/llm_as_judge.py
      data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
      --judge-model=${item.judge_llm}
    deps:
      - scripts/evaluation/llm_as_judge.py
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}
    outs:
      - data/experiments/predict/raw_vllm/${item.llm_dataset.dataset}/${item.llm_dataset.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/judge_${item.judge_llm}

  evaluate_llm_as_judge_on_fine_tuned:
    matrix:
      llm_dataset:
        - dataset: pl_court_swiss_franc_loans
          llm: llama_3.1_8b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: llama_3.2_3b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: mistral_nemo_instruct_2407
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: pllum_12b_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
        - dataset: pl_court_swiss_franc_loans
          llm: bielik_11b_v23_instruct
          prompt: info_extraction_annotated_json
          ie_schema: swiss_franc_loans
      seed: ${seeds}
      split:
        - annotated
      model_type:
        - fine_tuned_vllm
      judge_llm:
        - gpt-4.1-mini-2025-04-14
    cmd: >-
      PYTHONPATH=. python scripts/sft/llm_as_judge.py
      data/experiments/predict/${item.model_type}/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/predictions.json
      configs/ie_schema/swiss_franc_loans.yaml
      --judge-model=${item.judge_llm}
    deps:
      - scripts/sft/llm_as_judge.py
      - configs/ie_schema/swiss_franc_loans.yaml
      - data/experiments/predict/${item.model_type}/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/predictions.json
    outs:
      - data/experiments/predict/${item.model_type}/${item.llm_dataset.dataset}/${item.split}/${item.llm_dataset.llm}/${item.llm_dataset.prompt}/${item.llm_dataset.ie_schema}/seed_${item.seed}/llm_as_judge_${item.judge_llm}.json

  evaluate_llm_as_judge_on_preannotations:
    matrix:
      pred_schema:
        - pred_path: data/experiments/predict/raw/pl_court_swiss_franc_loans/test/gpt_4.1/
          schema: configs/ie_schema/swiss_franc_loans.yaml
        - pred_path: data/experiments/predict/raw/en_appealcourt_coded/test/gpt_4.1/
          schema: configs/ie_schema/en_appealcourt.yaml
      judge_llm:
        - gpt-4.1-mini-2025-04-14
    cmd: >-
      PYTHONPATH=. python scripts/sft/llm_as_judge.py
      ${item.pred_schema.pred_path}/predictions.json
      ${item.pred_schema.schema}
      --judge-model=${item.judge_llm}
    deps:
      - scripts/sft/llm_as_judge.py
      - ${item.pred_schema.schema}
      - ${item.pred_schema.pred_path}/predictions.json
    outs:
      - ${item.pred_schema.pred_path}/llm_as_judge_${item.judge_llm}.json

  summarize_metrics:
    matrix:
      dir:
        - data/experiments/predict/raw_vllm/en_appealcourt_coded/annotated
        - data/experiments/predict/raw_vllm/pl_court_swiss_franc_loans/annotated
        - data/experiments/predict/fine_tuned_vllm/pl_court_swiss_franc_loans/annotated
        - data/experiments/predict/raw/pl_court_swiss_franc_loans/test
        - data/experiments/predict/raw/en_appealcourt_coded/test
    cmd: >-
      PYTHONPATH=. python scripts/sft/summarize_metrics.py
      --root-dir ${item.dir}
    deps:
      - scripts/sft/summarize_metrics.py
    metrics:
      - ${item.dir}/metrics_ngram_summary.md:
          cache: false
      - ${item.dir}/metrics_judge_summary.md:
          cache: false
