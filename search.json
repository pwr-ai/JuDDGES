[
  {
    "objectID": "Dataset Cards/dataset_description_instruct.html",
    "href": "Dataset Cards/dataset_description_instruct.html",
    "title": "Dataset Card for JuDDGES/pl-court-instruct",
    "section": "",
    "text": "import datasets\nimport transformers\nimport warnings\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport pandas as pd\nimport polars as pl\nimport seaborn as sns\nimport yaml\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom IPython.display import display\n\n\nwarnings.filterwarnings('ignore')\nsns.set_theme(\"notebook\")\ntransformers.logging.set_verbosity_error()\ndatasets.logging.set_verbosity_error()\ndatasets.utils.disable_progress_bars()\nds = load_dataset(\"JuDDGES/pl-court-instruct\")\ndisplay(ds[\"train\"][0])\n:::",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)"
    ]
  },
  {
    "objectID": "Dataset Cards/dataset_description_instruct.html#dataset-creation",
    "href": "Dataset Cards/dataset_description_instruct.html#dataset-creation",
    "title": "Dataset Card for JuDDGES/pl-court-instruct",
    "section": "Dataset Creation",
    "text": "Dataset Creation\nFor details on the dataset creation, see the paper TBA and the code repository here.\n\nCuration Rationale\nCreated to enable cross-jurisdictional legal analytics.\n\n\nSource Data\n\nInitial Data Collection and Normalization\n\nUtilize the raw dataset JuDDGES/pl-court-raw.\nFirst, we identified information from metadata which is contained in text of the judgement. Therefore, the following fields were selected for extraction as targets:\n\ndate\njudges\nrecorder\nsignature\ncourt_name\ndepartment_name\nlegal_bases\n\nData filtering: In order to ensure high quality of the dataset, we performed filtering procedure, as described below.\n\nRemoval of judgements with missing values in targets - if any of the target field has missing value, entire judgement is discarded (information might still be contained in judgement text, and in such case the targets would be incorrect)\nCleaning judges field - in some examples, names of judges were concatenated into single name instead of being list of names, so we split them based on conjunction\nRemoving examples wherein targets are not in text - due to inherent errors in acquired data, some targets might be mistyped, hence we filter them out (Data cleaning removes 173297 examples, and dataset consists of 240851.)\n\nGenerating instructions: After cleaning we generate instructions for information extraction. Specifically, we define same prompt for each document, as follows:\nYou are extracting information from the Polish court judgments.\nExtract specified values strictly from the provided judgement. If information is not provided in the judgement, leave the field with null value.\nPlease return the response in the identical YAML format:\n'''yaml\ncourt_name: \"&lt;nazwa sądu, string containing the full name of the court&gt;\"\ndate: &lt;data, date in format YYYY-MM-DD&gt;\ndepartment_name: \"&lt;nazwa wydziału, string containing the full name of the court's department&gt;\"\njudges: \"&lt;sędziowie, list of judge full names&gt;\"\nlegal_bases: &lt;podstawy prawne, list of strings containing legal bases (legal regulations)&gt;\nrecorder: &lt;protokolant, string containing the name of the recorder&gt;\nsignature: &lt;sygnatura, string contraining the signature of the judgment&gt;\n'''\n=====\n{context}\n======\nwhere {context} is replaced by text of each judgement. We highlight that judgements are in Polish, hence to foster model responding in Polish, we provide name Polish names of the field in the prompt.\n\n\n\nWho are the source language producers?\nProduced by human legal professionals (judges, court clerks). Demographics was not analysed. Sourced from public court databases.\n\n\n\nAnnotations\n\nAnnotation process\nNo annotation was performed by us. All features were provided via API.\n\n\nWho are the annotators?\nAs above.\n\n\n\nPersonal and Sensitive Information\nPseudoanonymized to comply with GDPR (art. 4 sec. 5 GDPR).",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)"
    ]
  },
  {
    "objectID": "Dataset Cards/dataset_description_instruct.html#considerations-for-using-the-data",
    "href": "Dataset Cards/dataset_description_instruct.html#considerations-for-using-the-data",
    "title": "Dataset Card for JuDDGES/pl-court-instruct",
    "section": "Considerations for Using the Data",
    "text": "Considerations for Using the Data\n\nSocial Impact of Dataset\n[More Information Needed]\n\n\nDiscussion of Biases\n[More Information Needed]\n\n\nOther Known Limitations\n[More Information Needed]",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)"
    ]
  },
  {
    "objectID": "Dataset Cards/dataset_description_instruct.html#additional-information",
    "href": "Dataset Cards/dataset_description_instruct.html#additional-information",
    "title": "Dataset Card for JuDDGES/pl-court-instruct",
    "section": "Additional Information",
    "text": "Additional Information\n\nDataset Curators\n[More Information Needed]\n\n\nLicensing Information\n[More Information Needed]\n\n\nCitation Information\n[More Information Needed]",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)"
    ]
  },
  {
    "objectID": "Dataset Cards/dataset_description_instruct.html#statistics",
    "href": "Dataset Cards/dataset_description_instruct.html#statistics",
    "title": "Dataset Card for JuDDGES/pl-court-instruct",
    "section": "Statistics",
    "text": "Statistics\n\ndata = yaml.safe_load(ds[\"train\"][\"output\"][0].replace(\"```yaml\", \"\").replace(\"```\", \"\"))\ndata[\"date\"] = pd.to_datetime(data[\"date\"])\n\n\ndef parse_output(output: str) -&gt; dict:\n    data = yaml.safe_load(output.replace(\"```yaml\", \"\").replace(\"```\", \"\"))\n    data[\"date\"] = pd.to_datetime(data[\"date\"])\n    return data\n\nds = ds.map(parse_output, input_columns=\"output\", num_proc=20)\n\n\npl_ds = pl.concat([pl.from_arrow(ds[\"train\"].data.table), pl.from_arrow(ds[\"test\"].data.table)])\npl_ds = pl_ds.with_columns(pl.Series(name=\"subset\", values=[\"train\"] * len(ds[\"train\"]) + [\"test\"] * len(ds[\"test\"])))\n\n\ncourt_distribution = pl_ds.select([\"subset\", \"court_name\"]).group_by([\"subset\", \"court_name\"]).len().sort(\"len\", descending=True).to_pandas()\nax = sns.histplot(data=court_distribution, x=\"len\", hue=\"subset\", log_scale=True, kde=True, stat=\"percent\", common_norm=False )\nax.set(title=\"Distribution of judgments per court\", xlabel=\"#Judgements in single court\", ylabel=\"percent\")\nplt.show()\n\n\njudgements_per_year = pl_ds.select([\"subset\", \"date\"])[[\"subset\", \"date\"]]\njudgements_per_year = judgements_per_year.with_columns(judgements_per_year[\"date\"].dt.year()) \njudgements_per_year = judgements_per_year.group_by([\"subset\", \"date\"]).len().sort(\"date\")\njudgements_per_year = judgements_per_year.to_pandas()\njudgements_per_year[\"%\"] = judgements_per_year.groupby(\"subset\")[\"len\"].transform(lambda x: x / x.sum() * 100) \n\n_, ax = plt.subplots(1, 1, figsize=(10, 5))\nax = sns.pointplot(data=judgements_per_year, x=\"date\", y=\"%\", hue=\"subset\", linestyles=\"--\", ax=ax)\nax.set(xlabel=\"Year\", ylabel=\"% Judgements\", title=\"Yearly Number of Judgements\", yscale=\"log\")\nplt.xticks(rotation=90)\nplt.show()\n\n\nnum_judges = pl_ds.with_columns([pl.col(\"judges\").list.len().alias(\"num_judges\")]).select([\"subset\", \"num_judges\"]).to_pandas()\nax = sns.histplot(data=num_judges, x=\"num_judges\", hue=\"subset\", bins=num_judges[\"num_judges\"].nunique(), stat=\"percent\", common_norm=False)\nax.set(xlabel=\"#Judges per judgement\", ylabel=\"%\", title=\"#Judges per single judgement\")\nplt.show()\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n\ndef tokenize(batch: dict[str, list]) -&gt; list[int]: \n    tokenized = tokenizer(batch[\"context\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n    return {\"length\": tokenized[\"length\"]}\n\nds = ds.map(tokenize, batched=True, batch_size=16, remove_columns=[\"context\"], num_proc=20)\n\n\ncontext_len_train = ds[\"train\"].to_pandas()\ncontext_len_train[\"subset\"] = \"train\"\ncontext_len_test = ds[\"test\"].to_pandas()\ncontext_len_test[\"subset\"] = \"test\"\ncontext_len = pd.concat([context_len_train, context_len_test])\n\nax = sns.histplot(data=context_len, x=\"length\", bins=50, hue=\"subset\")\nax.set(xlabel=\"#Tokens\", ylabel=\"Count\", title=\"#Tokens distribution in context (llama-3 tokenizer)\", yscale=\"log\")\nax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x/1_000)}k'))\nplt.show()",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-instruct](https://huggingface.co/datasets/JuDDGES/pl-court-instruct)"
    ]
  },
  {
    "objectID": "Dataset Cards/03_Graph_Description.html",
    "href": "Dataset Cards/03_Graph_Description.html",
    "title": "Polish Court Judgments Graph",
    "section": "",
    "text": "We introduce a graph dataset of Polish Court Judgments. This dataset is primarily based on the JuDDGES/pl-court-raw. The dataset consists of nodes representing either judgments or legal bases, and edges connecting judgments to the legal bases they refer to. Also, the graph was cleaned from small disconnected components, leaving single giant component. Consequently, the resulting graph is bipartite. We provide the dataset in both JSON and PyG formats, each has different purpose. While structurally graphs in these formats are the same, their attributes differ.\nThe JSON format is intended for analysis and contains most of the attributes available in JuDDGES/pl-court-raw. We excluded some less-useful attributes and text content, which can be easily retrieved from the raw dataset and added to the graph as needed.\nThe PyG format is designed for machine learning applications, such as link prediction on graphs, and is fully compatible with the Pytorch Geometric framework.\nIn the following sections, we provide a more detailed explanation and use case examples for each format.\n\n\n\n\n\n\nfeature\nvalue\n\n\n\n\n#nodes\n369033\n\n\n#edges\n1131458\n\n\n#nodes (type=judgment)\n366212\n\n\n#nodes (type=legal_base)\n2819\n\n\navg(degree)\n6.132015294025195\n\n\n\n\n\n\npng\n\n\n\n\n\nThe JSON format contains graph node types differentiated by node_type attrbute. Each node_type has its additional corresponding attributes (see JuDDGES/pl-court-raw for detailed description of each attribute):\n\n\n\n\n\n\n\nnode_type\nattributes\n\n\n\n\njudgment\n_id,chairman,court_name,date,department_name,judges,node_type,publisher,recorder,signature,type\n\n\nlegal_base\nisap_id,node_type,title\n\n\n\n\n\nGraph the JSON format is saved in node-link format, and can be readily loaded with networkx library:\nimport json\nimport networkx as nx\nfrom huggingface_hub import hf_hub_download\n\nDATA_DIR = \"&lt;your_local_data_directory&gt;\"\nJSON_FILE = \"data/judgment_graph.json\"\nhf_hub_download(repo_id=\"JuDDGES/pl-court-graph\", repo_type=\"dataset\", filename=JSON_FILE, local_dir=DATA_DIR)\n\nwith open(f\"{DATA_DIR}/{JSON_FILE}\") as file:\n    g_data = json.load(file)\n\ng = nx.node_link_graph(g_data)\n\n\n\n# TBD\n\n\n\n\nThe PyTorch Geometric format includes embeddings of the judgment content, obtained with sdadas/mmlw-roberta-large for judgment nodes, and one-hot-vector identifiers for legal-base nodes (note that for efficiency one can substitute it with random noise identifiers, like in (Abboud et al., 2021)).\n\n\nIn order to load graph as pytorch geometric, one can leverage the following code snippet\nimport torch\nimport os\nfrom torch_geometric.data import InMemoryDataset, download_url\n\n\nclass PlCourtGraphDataset(InMemoryDataset):\n    URL = (\n        \"https://huggingface.co/datasets/JuDDGES/pl-court-graph/resolve/main/\"\n        \"data/pyg_judgment_graph.pt?download=true\"\n    )\n\n    def __init__(self, root_dir: str, transform=None, pre_transform=None):\n        super(PlCourtGraphDataset, self).__init__(root_dir, transform, pre_transform)\n        data_file, index_file = self.processed_paths\n        self.load(data_file)\n        self.judgment_idx_2_iid, self.legal_base_idx_2_isap_id = torch.load(index_file).values()\n\n    @property\n    def raw_file_names(self) -&gt; str:\n        return \"pyg_judgment_graph.pt\"\n\n    @property\n    def processed_file_names(self) -&gt; list[str]:\n        return [\"processed_pyg_judgment_graph.pt\", \"index_map.pt\"]\n\n    def download(self) -&gt; None:\n        os.makedirs(self.root, exist_ok=True)\n        download_url(self.URL + self.raw_file_names, self.raw_dir)\n\n    def process(self) -&gt; None:\n        dataset = torch.load(self.raw_paths[0])\n        data = dataset[\"data\"]\n\n        if self.pre_transform is not None:\n            data = self.pre_transform(data)\n\n        data_file, index_file = self.processed_paths\n        self.save([data], data_file)\n\n        torch.save(\n            {\n                \"judgment_idx_2_iid\": dataset[\"judgment_idx_2_iid\"],\n                \"legal_base_idx_2_isap_id\": dataset[\"legal_base_idx_2_isap_id\"],\n            },\n            index_file,\n        )\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({len(self)})\"\n\n\nds = PlCourtGraphDataset(root_dir=\"data/datasets/pyg\")\nprint(ds)\n\n\n\n# TBD"
  },
  {
    "objectID": "Dataset Cards/03_Graph_Description.html#dataset-description",
    "href": "Dataset Cards/03_Graph_Description.html#dataset-description",
    "title": "Polish Court Judgments Graph",
    "section": "",
    "text": "We introduce a graph dataset of Polish Court Judgments. This dataset is primarily based on the JuDDGES/pl-court-raw. The dataset consists of nodes representing either judgments or legal bases, and edges connecting judgments to the legal bases they refer to. Also, the graph was cleaned from small disconnected components, leaving single giant component. Consequently, the resulting graph is bipartite. We provide the dataset in both JSON and PyG formats, each has different purpose. While structurally graphs in these formats are the same, their attributes differ.\nThe JSON format is intended for analysis and contains most of the attributes available in JuDDGES/pl-court-raw. We excluded some less-useful attributes and text content, which can be easily retrieved from the raw dataset and added to the graph as needed.\nThe PyG format is designed for machine learning applications, such as link prediction on graphs, and is fully compatible with the Pytorch Geometric framework.\nIn the following sections, we provide a more detailed explanation and use case examples for each format."
  },
  {
    "objectID": "Dataset Cards/03_Graph_Description.html#dataset-statistics",
    "href": "Dataset Cards/03_Graph_Description.html#dataset-statistics",
    "title": "Polish Court Judgments Graph",
    "section": "",
    "text": "feature\nvalue\n\n\n\n\n#nodes\n369033\n\n\n#edges\n1131458\n\n\n#nodes (type=judgment)\n366212\n\n\n#nodes (type=legal_base)\n2819\n\n\navg(degree)\n6.132015294025195\n\n\n\n\n\n\npng"
  },
  {
    "objectID": "Dataset Cards/03_Graph_Description.html#json-format",
    "href": "Dataset Cards/03_Graph_Description.html#json-format",
    "title": "Polish Court Judgments Graph",
    "section": "",
    "text": "The JSON format contains graph node types differentiated by node_type attrbute. Each node_type has its additional corresponding attributes (see JuDDGES/pl-court-raw for detailed description of each attribute):\n\n\n\n\n\n\n\nnode_type\nattributes\n\n\n\n\njudgment\n_id,chairman,court_name,date,department_name,judges,node_type,publisher,recorder,signature,type\n\n\nlegal_base\nisap_id,node_type,title\n\n\n\n\n\nGraph the JSON format is saved in node-link format, and can be readily loaded with networkx library:\nimport json\nimport networkx as nx\nfrom huggingface_hub import hf_hub_download\n\nDATA_DIR = \"&lt;your_local_data_directory&gt;\"\nJSON_FILE = \"data/judgment_graph.json\"\nhf_hub_download(repo_id=\"JuDDGES/pl-court-graph\", repo_type=\"dataset\", filename=JSON_FILE, local_dir=DATA_DIR)\n\nwith open(f\"{DATA_DIR}/{JSON_FILE}\") as file:\n    g_data = json.load(file)\n\ng = nx.node_link_graph(g_data)\n\n\n\n# TBD"
  },
  {
    "objectID": "Dataset Cards/03_Graph_Description.html#pyg-format",
    "href": "Dataset Cards/03_Graph_Description.html#pyg-format",
    "title": "Polish Court Judgments Graph",
    "section": "",
    "text": "The PyTorch Geometric format includes embeddings of the judgment content, obtained with sdadas/mmlw-roberta-large for judgment nodes, and one-hot-vector identifiers for legal-base nodes (note that for efficiency one can substitute it with random noise identifiers, like in (Abboud et al., 2021)).\n\n\nIn order to load graph as pytorch geometric, one can leverage the following code snippet\nimport torch\nimport os\nfrom torch_geometric.data import InMemoryDataset, download_url\n\n\nclass PlCourtGraphDataset(InMemoryDataset):\n    URL = (\n        \"https://huggingface.co/datasets/JuDDGES/pl-court-graph/resolve/main/\"\n        \"data/pyg_judgment_graph.pt?download=true\"\n    )\n\n    def __init__(self, root_dir: str, transform=None, pre_transform=None):\n        super(PlCourtGraphDataset, self).__init__(root_dir, transform, pre_transform)\n        data_file, index_file = self.processed_paths\n        self.load(data_file)\n        self.judgment_idx_2_iid, self.legal_base_idx_2_isap_id = torch.load(index_file).values()\n\n    @property\n    def raw_file_names(self) -&gt; str:\n        return \"pyg_judgment_graph.pt\"\n\n    @property\n    def processed_file_names(self) -&gt; list[str]:\n        return [\"processed_pyg_judgment_graph.pt\", \"index_map.pt\"]\n\n    def download(self) -&gt; None:\n        os.makedirs(self.root, exist_ok=True)\n        download_url(self.URL + self.raw_file_names, self.raw_dir)\n\n    def process(self) -&gt; None:\n        dataset = torch.load(self.raw_paths[0])\n        data = dataset[\"data\"]\n\n        if self.pre_transform is not None:\n            data = self.pre_transform(data)\n\n        data_file, index_file = self.processed_paths\n        self.save([data], data_file)\n\n        torch.save(\n            {\n                \"judgment_idx_2_iid\": dataset[\"judgment_idx_2_iid\"],\n                \"legal_base_idx_2_isap_id\": dataset[\"legal_base_idx_2_isap_id\"],\n            },\n            index_file,\n        )\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({len(self)})\"\n\n\nds = PlCourtGraphDataset(root_dir=\"data/datasets/pyg\")\nprint(ds)\n\n\n\n# TBD"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JuDDGES",
    "section": "",
    "text": "JuDDGES stands for Judicial Decision Data Gathering, Encoding, and Sharing\nThe JuDDGES project aims to revolutionize the accessibility and analysis of judicial decisions across varied legal systems using advanced Natural Language Processing and Human-In-The-Loop technologies. It focuses on criminal court records from jurisdictions with diverse legal constitutions, including Poland and England & Wales. By overcoming barriers related to resources, language, data, and format inhomogeneity, the project facilitates the development and testing of theories on judicial decision-making and informs judicial policy and practice. Open software and tools produced by the project will enable extensive, flexible meta-annotation of legal texts, benefiting researchers and public legal institutions alike. This initiative not only advances empirical legal research by adopting Open Science principles but also creates the most comprehensive legal research repository in Europe, fostering cross-disciplinary and cross-jurisdictional collaboration.",
    "crumbs": [
      "JuDDGES"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "JuDDGES",
    "section": "Usage",
    "text": "Usage\n\nInstallation\n\nto install necessary dependencies use available Makefile, you can use python&gt;=3.10: make install\nif you want to run evaluation and fine-tuning with unsloth, use the following command with python=3.10 inside conda environment: make install_unsloth\n\n\n\nDataset creation\nThe specific details of dataset creation are available in scripts/README.md.\n\n\nFine tuning\nTo run evaluation or fine-tuning, run proper stages declared dvc.yaml (see DVC docs for details)",
    "crumbs": [
      "JuDDGES"
    ]
  },
  {
    "objectID": "index.html#project-details",
    "href": "index.html#project-details",
    "title": "JuDDGES",
    "section": "Project details",
    "text": "Project details\nThe JuDDGES project encompasses several Work Packages (WPs) designed to cover all aspects of its objectives, from project management to the open science practices and engaging early career researchers. Below is an overview of the project’s WPs based on the provided information:\n\nWP1: Project Management\nDuration: 24 Months\nMain Aim: To ensure the project’s successful completion on time and within budget. This includes administrative management, scientific and technological management, quality innovation and risk management, ethical and legal consideration, and facilitating open science.\n\n\nWP2: Gathering and Human Encoding of Judicial Decision Data\nDuration: 22 Months\nMain Aim: To establish the data foundation for developing and testing the project’s tools. This involves collating/gathering legal case records and judgments, developing a coding scheme, training human coders, making human-coded data available for WP3, facilitating human-in-loop coding for WP3, and enabling WP4 to make data open and reusable beyond the project team.\n\n\nWP3: NLP and HITL Machine Learning Methodological Development\nDuration: 24 Months\nMain Aim: To create a bridge between machine learning (led by WUST and MUHEC) and Open Science facilitation (by ELICO), focusing on the development and deployment of annotation methodologies. This includes baseline information extraction, intelligent inference methods for legal corpus data, and constructing an annotation tool through active learning and human-in-the-loop annotation methods.\n\n\nWP4: Open Science Practices & Engaging Early Career Researchers\nDuration: 12 Months\nMain Aim: To implement the Open Science policy of the call and engage with relevant early career researchers (ECRs). Objectives include providing open access to publication data and software, disseminating/exploiting project results, and promoting the project and its findings.\nEach WP includes specific tasks aimed at achieving its goals, involving collaboration among project partners and contributing to the overarching aim of the JuDDGES project​​.",
    "crumbs": [
      "JuDDGES"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "JuDDGES",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe universities involved in the JuDDGES project are:\n\nWroclaw University of Science and Technology (Poland)\nMiddlesex University London (UK)\nUniversity of Lyon 1 (France)​​.",
    "crumbs": [
      "JuDDGES"
    ]
  },
  {
    "objectID": "Data/analyze_en_judgements_texts.html",
    "href": "Data/analyze_en_judgements_texts.html",
    "title": "Analyze Text of England and Wales Judgements",
    "section": "",
    "text": "import json\nimport string\nfrom datasets import Dataset, DatasetDict, load_from_disk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom juddges.settings import DATA_PATH\n\n\npath_ = DATA_PATH / \"datasets\" / \"en\"\njsonl_file = path_ / \"england_wales_data_refined_7.jsonl\"\ndataset_path = path_ / \"en_judgements_dataset\"\n\n\ndata = []\nwith open(jsonl_file, 'r') as file:\n    for line in file:\n        data.append(json.loads(line))\n\ndataset = Dataset.from_json(jsonl_file)\ndataset_dict = DatasetDict({\"train\": dataset})\n\n# Save the dataset to disk\ndataset.save_to_disk(dataset_path)\n\n\n\n\n\n# Load the dataset from disk\nds = load_from_disk(dataset_path)\n\n\ndef tagger(item):\n    text = item[\"content\"]\n    dummy_tokens = text.split()\n\n    item[\"chars\"] = len(text)\n    item[\"num_dummy_tokens\"] = len(dummy_tokens)\n    item[\"num_non_ws_tokens\"] = sum(\n        1 for tok in dummy_tokens if any(char not in string.punctuation for char in tok.strip())\n    )\n\n    return item\n\n\nds = ds.map(tagger, num_proc=8)\nds.cleanup_cache_files()\n\n\n\n\n0\n\n\n\nstats = (\n    ds.select_columns([\"_id\", \"type\", \"appeal_type\", \"appeal_outcome\", \"chars\", \"num_dummy_tokens\", \"num_non_ws_tokens\"])\n    .to_pandas()\n    .convert_dtypes(dtype_backend=\"pyarrow\")\n)\nstats[\"type\"] = stats[\"type\"].astype(\"category\")\nstats.head()\n\n\n\n\n\n\n\n\n_id\ntype\nappeal_type\nappeal_outcome\nchars\nnum_dummy_tokens\nnum_non_ws_tokens\n\n\n\n\n0\nab0224364e4cf6562c82f8861d5268d4fa22b2ec45e0f7...\ncrown_court\n&lt;NA&gt;\n&lt;NA&gt;\n12444\n2229\n2155\n\n\n1\nd4630d93258ea51ecff4bc4015443b4eecf8d9b2e5b7c5...\nsupreme_court\nconviction\n&lt;NA&gt;\n20977\n3681\n3586\n\n\n2\n37183a714b626cfe98081ac0250c804f992f340281f6d2...\ncrown_court\n&lt;NA&gt;\n&lt;NA&gt;\n40570\n7199\n7097\n\n\n3\nb41933b19505ab8767ce30faf8db9524f737ec5ac2c17e...\ncrown_court\n&lt;NA&gt;\n&lt;NA&gt;\n19459\n3515\n3432\n\n\n4\n418382a2a6c0c32d3d2bd4cb7b39e1ba259dc6bf56a78e...\ncrown_court\n&lt;NA&gt;\nallowed\n10352\n1879\n1793\n\n\n\n\n\n\n\n\nax = sns.histplot(\n    x=stats[\"num_non_ws_tokens\"],\n    log_scale=True,\n    bins=50,\n)\nax.set(title=\"#tokens distribution\")\n\n\n\n\n\n\n\n\n\ncourt_type_card_order = stats[\"type\"].value_counts().index.tolist()\ncourt_type_data = stats[\"type\"].value_counts().plot.barh(logx=True, title=\"Types cardinality\")\n\n\n\n\n\n\n\n\n\nappeal_type_card_order = stats[\"appeal_type\"].value_counts().index.tolist()\nappeal_type_data = stats[\"appeal_type\"].value_counts().plot.barh(logx=True, title=\"Types cardinality\")\n\n\n\n\n\n\n\n\n\nappeal_outcome_card_order = stats[\"appeal_outcome\"].value_counts().index.tolist()\nappeal_outcome_data = stats[\"appeal_outcome\"].value_counts().plot.barh(logx=True, title=\"Types cardinality\")\n\n\n\n\n\n\n\n\n\n# sns.displot(data=stats, x=\"num_non_ws_tokens\", col=\"type\", col_wrap=3, log_scale=(True, False), facet_kws=dict(sharey=False, sharex=False), kind=\"hist\", bins=25)\n\n_, ax = plt.subplots(figsize=(8, 12))\nax.set(title=\"Per type text length ditribution\")\nsns.boxenplot(data=stats, y=\"type\", x=\"num_non_ws_tokens\", order=court_type_card_order, log_scale=True)\n\n\n\n\n\n\n\n\n\n# sns.displot(data=stats, x=\"num_non_ws_tokens\", col=\"type\", col_wrap=3, log_scale=(True, False), facet_kws=dict(sharey=False, sharex=False), kind=\"hist\", bins=25)\n\n_, ax = plt.subplots(figsize=(8, 12))\nax.set(title=\"Per type text length ditribution\")\nsns.boxenplot(data=stats, y=\"appeal_type\", x=\"num_non_ws_tokens\", order=appeal_type_card_order, log_scale=True)\n\n\n\n\n\n\n\n\n\n# sns.displot(data=stats, x=\"num_non_ws_tokens\", col=\"type\", col_wrap=3, log_scale=(True, False), facet_kws=dict(sharey=False, sharex=False), kind=\"hist\", bins=25)\n\n_, ax = plt.subplots(figsize=(8, 12))\nax.set(title=\"Per type text length ditribution\")\nsns.boxenplot(data=stats, y=\"appeal_outcome\", x=\"num_non_ws_tokens\", order=appeal_outcome_card_order, log_scale=True)\n\n\n\n\n\n\n\n\n\nTokenize\n\nfrom transformers import AutoTokenizer\n\nNone of PyTorch, TensorFlow &gt;= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large\")\nds = ds.map(\n    lambda examples: tokenizer(examples[\"content\"], padding=False, truncation=False),\n    batched=True,\n    num_proc=44,\n)\n\n\ntokenized = []\nfor item in ds:\n    tokenized.append({\"num_tokens\": len(item[\"input_ids\"])})\n\n\nnum_tokens = [item['num_tokens'] for item in tokenized]\nfiltered_tokens = [token for token in num_tokens if token &lt;= 40000]\n\n\nsns.histplot(filtered_tokens, bins=100)\n\n\n\n\n\n\n\n\n\n# Plot the box plot\nplt.figure(figsize=(6, 6))\nsns.boxplot(filtered_tokens)\nplt.show()",
    "crumbs": [
      "Data",
      "Analyze Text of England and Wales Judgements"
    ]
  },
  {
    "objectID": "Data/graph_dataset_description.html",
    "href": "Data/graph_dataset_description.html",
    "title": "Graph dataset analysis",
    "section": "",
    "text": "import json\nimport networkx as nx\nfrom tabulate import tabulate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom omegaconf import OmegaConf\n\nsns.set_theme(\"notebook\")\n# load the graph\nwith open(\"../../data/datasets/pl/graph/data/judgment_graph.json\") as file:\n    g_data = json.load(file)\n\ng = nx.node_link_graph(g_data)\nsrc_nodes, target_nodes = nx.bipartite.sets(g)\nconfig = OmegaConf.load(\"../../data/datasets/pl/graph/metadata.yaml\")\nOmegaConf.resolve(config)",
    "crumbs": [
      "Data",
      "Graph dataset analysis"
    ]
  },
  {
    "objectID": "Data/graph_dataset_description.html#dataset-statistics",
    "href": "Data/graph_dataset_description.html#dataset-statistics",
    "title": "Graph dataset analysis",
    "section": "Dataset statistics",
    "text": "Dataset statistics\n\nstats = [\n    [\"#nodes\", g.number_of_nodes()],\n    [\"#edges\", g.number_of_edges()],\n    [\"#nodes (type=`judgement`)\", len(src_nodes)],\n    [\"#nodes (type=`legal_base`)\", len(target_nodes)],\n    [\"avg(degree)\", round(sum(dict(g.degree()).values()) / g.number_of_nodes(), 2)],\n]\nprint(tabulate(stats, headers=[\"feature\", \"value\"], tablefmt=\"github\", floatfmt=\".2f\"))\n\n| feature                    |      value |\n|----------------------------|------------|\n| #nodes                     |  369033.00 |\n| #edges                     | 1131458.00 |\n| #nodes (type=`judgement`)  |  366213.00 |\n| #nodes (type=`legal_base`) |    2820.00 |\n| avg(degree)                |       6.13 |\n\n\n\nsrc_degs = list(dict(nx.degree(g, nbunch=src_nodes)).values())\ntarget_degs = list(dict(nx.degree(g, nbunch=target_nodes)).values())\n\n_, (ax_src, ax_target) = plt.subplots(1, 2, figsize=(12, 5))\nax = sns.histplot(src_degs, bins=20, ax=ax_src)\nax.set(xlabel=\"degree\", ylabel=\"count\", title=r\"$\\mathtt{judgement}$ degree distribution\", yscale=\"log\")\n\nax = sns.histplot(target_degs, bins=20, ax=ax_target)\nax.set(xlabel=\"degree\", ylabel=\"count\", title=r\"$\\mathtt{legal\\_base}$ degree distribution\", yscale=\"log\")\n\nplt.show()",
    "crumbs": [
      "Data",
      "Graph dataset analysis"
    ]
  },
  {
    "objectID": "Data/graph_analysis.html",
    "href": "Data/graph_analysis.html",
    "title": "Local subgraphs analysis",
    "section": "",
    "text": "import itertools\nimport json\n\nimport polars as pl\nimport networkx as nx\nimport seaborn as sns\nimport pandas as pd\nimport random\nimport openai\nfrom langchain_core.utils.json import parse_json_markdown\nfrom functools import partial\nfrom tqdm.auto import tqdm\n\nsns.set_theme(\"notebook\")\n\n\n# load the graph\nwith open(\"../../data/datasets/pl/graph/data/judgment_graph.json\") as file:\n    g_data = json.load(file)\n\ng = nx.node_link_graph(g_data)\nsrc_nodes, target_nodes = nx.bipartite.sets(g)\n\n\nds = pl.scan_parquet(\"../../data/datasets/pl/raw/*.parquet\")\n\n\nInvestigate local parts of graph\n\nExtract local graph\n\n# sets node degree as its attribute\nnx.set_node_attributes(g, dict(nx.degree(g)), \"degree\")\n\n\ndeg_sorted_nodes = sorted(g.nodes(data=True), key=lambda x: x[1][\"degree\"], reverse=True)\n\ndef get_legal_bases_with_deg(deg: int) -&gt; list[int]:\n    return [n_id for n_id, data in deg_sorted_nodes if data[\"degree\"] == deg and n_id in target_nodes]\n\ndef get_judgments_of_legal_base(legal_base_id: int) -&gt; list[int]:\n    dg = g.to_directed()\n    src_nodes = list(dg.predecessors(legal_base_id))\n    target_nodes = list(itertools.chain.from_iterable(dg.successors(n_id) for n_id in src_nodes))\n    return src_nodes + target_nodes\n\n\nLB = get_legal_bases_with_deg(4)[0]\nTITLE = g.nodes[LB][\"title\"]\nneighborhood = get_judgments_of_legal_base(LB)\nprint(f\"Found nodes: {len(neighborhood)=}\")\n\n\nsg = nx.induced_subgraph(g, nbunch=neighborhood)\n\n\ncases = pd.DataFrame.from_dict(dict(sg.nodes(data=True)), orient=\"index\").reset_index().sort_values([\"node_type\", \"date\"])\ncase_ids = cases[\"_id\"].dropna().tolist()\n\ncases_text= ds.select([\"_id\", \"text\"]).filter(pl.col(\"_id\").is_in(case_ids)).collect()\ncases = cases[[\"index\", \"_id\"]].merge(cases_text.to_pandas(), on=\"_id\", how=\"right\")\ncases.head()\n\n\n\nSummarize judgments\n\nclient = openai.OpenAI(\n    base_url=\"http://localhost:8000/v1\",\n    api_key = \"sk-no-key-required\"\n)\n\nllm_input = \"\\n\\n\".join([t[:3000] for t in cases_text.to_dict(as_series=False)[\"text\"]])\n\nINPUT_PROMPT = \"\"\"\nYou are an AI tasked with summarizing multiple Polish court judgments. Always response in English, use formal language.\nFirst, provide an overall_summary which is a single sentence that encapsulates the common topic of all the judgments, don't be too general.\nThen, for each judgment, provide a one-sentence judgment_summary, including the main reason for the decision, preserve order of judgments. \nFor each judgment provide keyphrases summarizing it.\n\nSummarize followint judgments:\n====\n{context}\n====\n\nFormat response as JSON:\n``json\n{{\n    overall_summary: string,\n    judgment_summaries: list of string,\n    keyphrases: list of lists of string,\n}}\n```\n\"\"\"\n\ncompletion = client.chat.completions.create(\nmodel=\"not-required\",\nmessages=[\n    {\"role\": \"user\", \"content\": INPUT_PROMPT.format(context=llm_input)}\n]\n)\n\nresponse = completion.choices[0].message.content\n\ntry:\n    summary = parse_json_markdown(response)\n    print(summary)\nexcept Exception:\n    print(\"Couldn't parse, raw response:\")\n    print(response)\n\n\niid_2_index = {item[\"_id\"]: item[\"index\"] for item in cases[[\"index\", \"_id\"]].to_dict(\"records\")}\nsummary_node_attr = {iid_2_index[iid]: text for iid, text in zip(cases_text[\"_id\"].to_list(), summary[\"judgment_summaries\"])}\nkp_node_attr = {iid_2_index[iid]: text for iid, text in zip(cases_text[\"_id\"].to_list(), summary[\"keyphrases\"])}\nnx.set_node_attributes(sg, summary_node_attr, name=\"summary\")\nnx.set_node_attributes(sg, kp_node_attr, name=\"keyphrases\")\n\n\n\nTranslate legal-legal base names\n\nTRANSLATION_PROMPT = \"\"\"\nYou are an AI assistant asked to translate name of Polish legal acts to Ensligh.\nProvide shortest possible translations, remove dates and unimportant details.\nReturn only translation, without any additional output.\nExample:\n- Ustawa z dnia 23 kwietnia 1964 r. - Kodeks cywilny\n- Civil Code (1964)\n\nTranslate this legal act name: {context}\n\"\"\"\n\n\nresults = {}\nfor iid, name in tqdm(nx.get_node_attributes(sg, \"title\").items()):\n    completion = client.chat.completions.create(\n    model=\"not-required\",\n    messages=[\n        {\"role\": \"user\", \"content\": TRANSLATION_PROMPT.format(context=name)}\n    ]\n    )\n    results[iid] = [completion.choices[0].message.content]\n\nnx.set_node_attributes(sg, results, \"keyphrases\")\n\n\n\nVisualize\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, LabelSet\nfrom bokeh.plotting import figure\nfrom bokeh.plotting import from_networkx\nfrom bokeh.transform import linear_cmap\noutput_notebook()\n\n\nHOVER_TOOLTIPS = [\n    (\"Date\", \"@date\"),\n    (\"Summary\", \"@summary\"),\n    (\"ISAP\", \"@isap_id\"),\n]\n\nCOLOR_MAP = {\n    \"judgment\": 0,\n    \"legal_base\": 1,\n}\n\nnx.set_node_attributes(sg, {n_id: COLOR_MAP[n_data[\"node_type\"]] for n_id, n_data in sg.nodes(data=True)}, name=\"nt\")\ncolor_by_this_attribute = 'nt'\ncolor_palette = (\"#EA1D15\", \"#15E2EA\")\n\nplot = figure(\n    tooltips = HOVER_TOOLTIPS,\n    tools=\"pan,wheel_zoom,save,reset\", \n    active_scroll='wheel_zoom', \n    x_range=Range1d(-10.1, 10.1), \n    y_range=Range1d(-10.1, 10.1),\n    width=1_200,\n    height=600,\n)\n\nplot.xgrid.visible = False\nplot.ygrid.visible = False\nplot.xaxis.visible = False\nplot.yaxis.visible = False\nn_ids = [n_id for n_id in sg.nodes if sg.nodes[n_id][\"node_type\"]==\"judgment\"]\nn_ids_2 = [n_id for n_id in sg.nodes if sg.nodes[n_id][\"node_type\"]==\"legal_base\"]\nnetwork_graph = from_networkx(sg, partial(nx.bipartite_layout, nodes=n_ids), scale=10, center=(0, 0))\n\n#Set node sizes and colors according to node degree (color as spectrum of color palette)\nminimum_value_color = min(network_graph.node_renderer.data_source.data[color_by_this_attribute])\nmaximum_value_color = max(network_graph.node_renderer.data_source.data[color_by_this_attribute])\nnetwork_graph.node_renderer.glyph = Circle(radius=0.30, fill_color=linear_cmap(color_by_this_attribute, color_palette, minimum_value_color, maximum_value_color))\n\n#Set edge opacity and width\nnetwork_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n\nx, y = zip(*network_graph.layout_provider.graph_layout.values())\nnode_labels = [\",\".join(sg.nodes[index][\"keyphrases\"]) for index in n_ids + n_ids_2]\nsource = ColumnDataSource({'x': x, 'y': y, 'name': [node_labels[i] for i in range(len(x))]})\nlabels = LabelSet(x='x', y='y', text='name', source=source, background_fill_color='white', text_font_size='14px', background_fill_alpha=1.0)\nplot.renderers.append(labels)\n\nplot.renderers.append(network_graph)\n\nshow(plot)\n\n\n\n\nCommunity detection\n\ndef connected_legal_bases(g: nx.Graph, nbunch: list):\n    nbunch = set(nbunch)\n    return list(set(target_id for src_id, target_id in g.edges if src_id in nbunch))\n\n\ndef sample_subgraph_randomly(g: nx.Graph, k: int) -&gt; nx.Graph:\n    sampled_nodes = random.sample(list(src_nodes), k=k)\n    subgraph_node_ids = sampled_nodes + connected_legal_bases(g, sampled_nodes)\n    return nx.induced_subgraph(g, nbunch=subgraph_node_ids)\n\n\n# sg = sample_subgraph_randomly(g, k=5_000)\nsg = g\nprint(f\"{len(sg.edges)=}\")\n\n\ncommunities = list(nx.community.louvain_communities(sg, resolution=3))\n# communities = list(nx.community.label_propagation_communities(sg))\nprint(f\"{len(communities)=}\")\n\n\nax = sns.histplot([len(c) for c in communities])\nax.set(title=\"Community size distribution\", yscale=\"log\")\n\n\ncommunitiy_sizes = {idx: len(c) for idx, c in enumerate(communities)}",
    "crumbs": [
      "Data",
      "Local subgraphs analysis"
    ]
  },
  {
    "objectID": "Data/analyse_en_dataset.html",
    "href": "Data/analyse_en_dataset.html",
    "title": "Analyse England and Wales Dataset",
    "section": "",
    "text": "import polars as pl\nfrom datasets import load_from_disk\n\nfrom juddges.settings import DATA_PATH\n\n\npath_ = DATA_PATH / \"datasets\" / \"en\"\ndataset_path = path_ / \"en_judgements_dataset\"\nds = load_from_disk(dataset_path)\n\n\nds\n\nDataset({\n    features: ['_id', 'citation', 'signature', 'date', 'publicationDate', 'type', 'excerpt', 'content', 'judges', 'caseNumbers', 'citation_references', 'legislation', 'file_name', 'appeal_type', 'appeal_outcome', 'xml_uri', 'uri'],\n    num_rows: 6154\n})\n\n\n\ndf = ds.to_pandas()\npl_df = pl.DataFrame(df)\n\n\npl_df = pl_df.with_columns([\n    pl.col(\"date\").cast(pl.Utf8),\n    pl.col(\"publicationDate\").cast(pl.Utf8),\n])\n\n# Define date format\ndt_fmt = \"%Y-%m-%d %H:%M:%S%.f %Z\"\n\n# Perform column transformations\npl_df = pl_df.with_columns([\n    pl.col(\"date\").str.strptime(pl.Datetime, format=dt_fmt),\n    pl.col(\"publicationDate\").str.strptime(pl.Datetime, format=dt_fmt),\n    pl.col(\"type\").cast(pl.Categorical),\n    pl.col(\"appeal_type\").cast(pl.Categorical),\n    pl.col(\"appeal_outcome\").cast(pl.Categorical)\n])\n\n# Display the first few rows of the transformed DataFrame\nprint(pl_df.head())\n\nshape: (5, 17)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ _id       ┆ citation  ┆ signature ┆ date      ┆ … ┆ appeal_ty ┆ appeal_ou ┆ xml_uri   ┆ uri      │\n│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ pe        ┆ tcome     ┆ ---       ┆ ---      │\n│ str       ┆ str       ┆ str       ┆ datetime[ ┆   ┆ ---       ┆ ---       ┆ str       ┆ str      │\n│           ┆           ┆           ┆ ns]       ┆   ┆ cat       ┆ cat       ┆           ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ ab0224364 ┆ [2008]    ┆ EWCA_Crim ┆ null      ┆ … ┆ null      ┆ null      ┆ https://c ┆ https:// │\n│ e4cf6562c ┆ EWCA Crim ┆ _2952     ┆           ┆   ┆           ┆           ┆ aselaw.na ┆ caselaw. │\n│ 82f8861d5 ┆ 2952      ┆           ┆           ┆   ┆           ┆           ┆ tionalarc ┆ national │\n│ 268d4…    ┆           ┆           ┆           ┆   ┆           ┆           ┆ hives…    ┆ archives │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n│ d4630d932 ┆ [2006]    ┆ EWCA_Crim ┆ null      ┆ … ┆ convictio ┆ null      ┆ https://c ┆ https:// │\n│ 58ea51ecf ┆ EWCA Crim ┆ _3187     ┆           ┆   ┆ n         ┆           ┆ aselaw.na ┆ caselaw. │\n│ f4bc40154 ┆ 3187      ┆           ┆           ┆   ┆           ┆           ┆ tionalarc ┆ national │\n│ 43b4e…    ┆           ┆           ┆           ┆   ┆           ┆           ┆ hives…    ┆ archives │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n│ 37183a714 ┆ [2012]    ┆ EWCA_Crim ┆ null      ┆ … ┆ null      ┆ null      ┆ https://c ┆ https:// │\n│ b626cfe98 ┆ EWCA Crim ┆ _1840     ┆           ┆   ┆           ┆           ┆ aselaw.na ┆ caselaw. │\n│ 081ac0250 ┆ 1840      ┆           ┆           ┆   ┆           ┆           ┆ tionalarc ┆ national │\n│ c804f…    ┆           ┆           ┆           ┆   ┆           ┆           ┆ hives…    ┆ archives │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n│ b41933b19 ┆ [2014]    ┆ EWCA_Crim ┆ null      ┆ … ┆ null      ┆ null      ┆ https://c ┆ https:// │\n│ 505ab8767 ┆ EWCA Crim ┆ _1730     ┆           ┆   ┆           ┆           ┆ aselaw.na ┆ caselaw. │\n│ ce30faf8d ┆ 1730      ┆           ┆           ┆   ┆           ┆           ┆ tionalarc ┆ national │\n│ b9524…    ┆           ┆           ┆           ┆   ┆           ┆           ┆ hives…    ┆ archives │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n│ 418382a2a ┆ [2018]    ┆ EWCA_Crim ┆ null      ┆ … ┆ null      ┆ allowed   ┆ https://c ┆ https:// │\n│ 6c0c32d3d ┆ EWCA Crim ┆ _2189     ┆           ┆   ┆           ┆           ┆ aselaw.na ┆ caselaw. │\n│ 2bd4cb7b3 ┆ 2189      ┆           ┆           ┆   ┆           ┆           ┆ tionalarc ┆ national │\n│ 9e1ba…    ┆           ┆           ┆           ┆   ┆           ┆           ┆ hives…    ┆ archives │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n\n\n\npl_df.describe()\n\n\nshape: (9, 18)\n\n\n\nstatistic\n_id\ncitation\nsignature\ndate\npublicationDate\ntype\nexcerpt\ncontent\njudges\ncaseNumbers\ncitation_references\nlegislation\nfile_name\nappeal_type\nappeal_outcome\nxml_uri\nuri\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nf64\nf64\nf64\nf64\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"count\"\n\"6154\"\n\"6154\"\n\"6154\"\n\"0\"\n\"6154\"\n\"6154\"\n\"6058\"\n\"6154\"\n6115.0\n4934.0\n1392.0\n1826.0\n\"6154\"\n\"834\"\n\"1368\"\n\"6154\"\n\"6154\"\n\n\n\"null_count\"\n\"0\"\n\"0\"\n\"0\"\n\"6154\"\n\"0\"\n\"0\"\n\"96\"\n\"0\"\n39.0\n1220.0\n4762.0\n4328.0\n\"0\"\n\"5320\"\n\"4786\"\n\"0\"\n\"0\"\n\n\n\"mean\"\nnull\nnull\nnull\nnull\n\"2013-10-13 09:…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"std\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"min\"\n\"001d3b389f60bf…\n\"[2003] EWCA Cr…\n\"EWCA_(Crim)_14…\nnull\n\"2003-01-04 00:…\nnull\n\"********REPORT…\n\" 2020] EWCA Cr…\nnull\nnull\nnull\nnull\n\"2003_01_04-1.x…\nnull\nnull\n\"https://casela…\n\"https://casela…\n\n\n\"25%\"\nnull\nnull\nnull\nnull\n\"2008-06-11 00:…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"50%\"\nnull\nnull\nnull\nnull\n\"2012-11-29 00:…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"75%\"\nnull\nnull\nnull\nnull\n\"2019-06-07 00:…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"max\"\n\"ffffb6552ad898…\n\"[2024] EWCA Cr…\n\"Ewca_Crim_664\"\nnull\n\"2024-05-22 00:…\nnull\n\"…WARNING: repo…\n\"…WARNING: repo…\nnull\nnull\nnull\nnull\n\"2024_05_22-615…\nnull\nnull\n\"https://casela…\n\"https://casela…\n\n\n\n\n\n\n\npl_df[\"type\"].value_counts()\n\n\nshape: (7, 2)\n\n\n\ntype\ncount\n\n\ncat\nu32\n\n\n\n\n\"crown_court\"\n5472\n\n\n\"supreme_court\"\n660\n\n\n\"martial_court\"\n11\n\n\n\"high_court_adm…\n2\n\n\n\"high_court_div…\n7\n\n\n\"civil_criminal…\n1\n\n\n\"division_court…\n1\n\n\n\n\n\n\n\npl_df[\"appeal_type\"].value_counts()\n\n\nshape: (3, 2)\n\n\n\nappeal_type\ncount\n\n\ncat\nu32\n\n\n\n\n\"conviction\"\n496\n\n\nnull\n5320\n\n\n\"sentence\"\n338\n\n\n\n\n\n\n\npl_df[\"appeal_outcome\"].value_counts()\n\n\nshape: (5, 2)\n\n\n\nappeal_outcome\ncount\n\n\ncat\nu32\n\n\n\n\nnull\n4786\n\n\n\"granted\"\n20\n\n\n\"dismissed\"\n586\n\n\n\"refused\"\n65\n\n\n\"allowed\"\n697\n\n\n\n\n\n\n\nprint(f\"Missing content: {pl_df['content'].null_count() / len(pl_df)}\")\nprint(f\"Missing excerpt: {pl_df['excerpt'].null_count() / len(pl_df)}\")\n\nMissing content: 0.0\nMissing excerpt: 0.015599610009749756\n\n\n\npl_df[\"excerpt\"].str.strip_chars().str.len_chars().to_pandas().plot.hist(\n    bins=50, log=True, title=\"Excerpt #chars distribution\"\n)\n\n\n\n\n\n\n\n\n\npl_df[\"excerpt\"]\n\n\nshape: (6_154,)\n\n\n\nexcerpt\n\n\nstr\n\n\n\n\n\"No. 2008/03296…\n\n\n\"Neutral Citati…\n\n\n\"Neutral Citati…\n\n\n\"Neutral Citati…\n\n\n\"No: 201802356 …\n\n\n…\n\n\n\"Neutral Citati…\n\n\n\"Case No: 2002/…\n\n\n\"Neutral Citati…\n\n\n\"Case No: 20030…\n\n\n\"2017/05382/B1 …\n\n\n\n\n\n\n\npl_df[\"excerpt\"].str.strip_chars().str.len_chars().to_pandas()\n\n0       500.0\n1       500.0\n2       499.0\n3       500.0\n4       499.0\n        ...  \n6149    499.0\n6150    500.0\n6151    500.0\n6152    499.0\n6153    499.0\nName: excerpt, Length: 6154, dtype: float64",
    "crumbs": [
      "Data",
      "Analyse England and Wales Dataset"
    ]
  },
  {
    "objectID": "Data/hybrid_search.html",
    "href": "Data/hybrid_search.html",
    "title": "Example of hybrid search for our indexed data",
    "section": "",
    "text": "from dotenv import load_dotenv\n\n\nload_dotenv(\"../../.env\")\n\nTrue\n\n\n\nfrom juddges.retrieval.mongo_hybrid_search import run_hybrid_search\n\n\nfrom os import environ\n\n\nfrom pymongo import MongoClient\n\n\nclient = MongoClient(environ[\"MONGO_URI\"])\n\n\ncollection = client.get_database(\"datasets\").get_collection(\"pl-court\")\n\n\n# collection.find_one()\n\n\nfrom sentence_transformers import SentenceTransformer\n\n/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from tqdm.autonotebook import tqdm, trange\n\n\n\nmodel = SentenceTransformer(\"sdadas/mmlw-roberta-large\")\n\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\n\n\nquery = \"kara śmierci\"\n\n\nembedding = model.encode(query).tolist()\n\n\n# embedding\n\n\nresults = list(\n    run_hybrid_search(\n        collection=collection,\n        collection_name=\"pl-court\",\n        query=query,\n        embedding=embedding,\n    )\n)\n\n\nresults",
    "crumbs": [
      "Data",
      "Example of hybrid search for our indexed data"
    ]
  },
  {
    "objectID": "Data/analyse_sft.html",
    "href": "Data/analyse_sft.html",
    "title": "SFT results inspection",
    "section": "",
    "text": "import warnings\nimport json\nfrom multiprocessing import Pool\nfrom statistics import mean\nfrom typing import Any\nfrom pathlib import Path\n\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom ipywidgets import interact\n\nfrom juddges.utils.misc import parse_yaml\nfrom juddges.metrics.info_extraction import evaluate_extraction\n\npd.options.display.float_format = '{:,.3f}'.format\nwarnings.filterwarnings('ignore', message=\"To copy construct from a tensor, it is recommended to use\")\n\n\nCompare metrics\n\nresults = []\nfor f in  Path(\"../../data/experiments/predict/pl-court-instruct\").glob(\"metrics_*.json\"):\n    model_name = f.stem.replace(\"metrics_\", \"\")\n    with f.open() as file:\n        m_res = json.load(file)\n        results.append(\n            {\"llm\": model_name}\n            | {\"full_text_chrf\": m_res[\"full_text_chrf\"]}\n            | m_res[\"field_chrf\"]\n        )\n\npd.DataFrame(results).sort_values(\"llm\")\n\n\n\n\n\n\n\n\nllm\nfull_text_chrf\ncourt_name\ndate\ndepartment_name\njudges\nlegal_bases\nrecorder\nsignature\n\n\n\n\n2\nMeta-Llama-3-8B-Instruct\n0.247\n0.862\n0.971\n0.833\n0.882\n0.287\n0.805\n0.778\n\n\n0\nMistral-7B-Instruct-v0.2\n0.432\n0.839\n0.922\n0.850\n0.879\n0.333\n0.837\n0.145\n\n\n3\nMistral-7B-Instruct-v0.2-fine-tuned\n0.772\n0.987\n0.990\n0.965\n0.952\n0.600\n0.979\n0.972\n\n\n4\nUnsloth-Llama-3-8B-Instruct-fine-tuned\n0.828\n0.995\n0.989\n0.986\n0.977\n0.601\n0.993\n0.994\n\n\n1\nUnsloth-Mistral-7B-Instruct-v0.3\n0.477\n0.830\n0.987\n0.900\n0.870\n0.419\n0.943\n0.567\n\n\n5\nUnsloth-Mistral-7B-Instruct-v0.3-fine-tuned\n0.798\n0.995\n0.988\n0.986\n0.967\n0.608\n0.987\n0.976\n\n\n\n\n\n\n\n\n\nInspect results\n\nOUTPUTS_PATH = \"../../data/experiments/predict/pl-court-instruct/outputs_Unsloth-Llama-3-8B-Instruct-fine-tuned.json\"\n\nwith open(OUTPUTS_PATH) as file:\n    data = json.load(file)\n\n\ndef eval_item(item: dict[str, Any]) -&gt; dict[str, Any]:\n    item[\"metrics\"] = evaluate_extraction([item])\n    item[\"metrics\"][\"mean_field\"] = mean(item[\"metrics\"][\"field_chrf\"].values())\n    item[\"gold\"] = parse_yaml(item[\"gold\"])\n    try:\n        item[\"answer\"] = parse_yaml(item[\"answer\"])\n    except:\n        item[\"answer\"] = None\n    return item\n\nnum_invalid_answers = 0\nresults = []\nwith Pool(10) as pool:\n    for item in tqdm(pool.imap(eval_item, data), total=len(data)):\n        results.append(item)\n        if item[\"answer\"] is None:\n            num_invalid_answers += 1\n\nprint(f\"Number of invalid answers: {num_invalid_answers} / {len(data)}\")\n\n\n\n\nNumber of invalid answers: 224 / 2000\n\n\n\ndata_valid = [item for item in results if item[\"answer\"] is not None]\ndata_valid = sorted(data_valid, key=lambda x: x[\"metrics\"][\"mean_field\"])\n\ndef item_to_df(idx: int) -&gt; pd.DataFrame:\n    item = data_valid[idx]\n    return pd.DataFrame({\n        \"gold\": item[\"gold\"],\n        \"answer\": item[\"answer\"],\n        \"metrics\": item[\"metrics\"][\"field_chrf\"],\n    })\n\n\ninteract(item_to_df, idx=range(len(data_valid)));",
    "crumbs": [
      "Data",
      "SFT results inspection"
    ]
  },
  {
    "objectID": "Data/dataset_description.html",
    "href": "Data/dataset_description.html",
    "title": "Raw & Instruct Datasets Analyses",
    "section": "",
    "text": "from datasets import load_dataset\nimport pandas as pd\nimport polars as pl\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom transformers import AutoTokenizer\nfrom pathlib import Path\n\nsns.set_theme(\"notebook\")\nraw_ds = pl.scan_parquet(source=\"../../data/datasets/pl/raw/*\")\nraw_ds.columns\n\n['_id',\n 'signature',\n 'date',\n 'publicationDate',\n 'lastUpdate',\n 'courtId',\n 'departmentId',\n 'type',\n 'excerpt',\n 'content',\n 'chairman',\n 'decision',\n 'judges',\n 'legalBases',\n 'publisher',\n 'recorder',\n 'references',\n 'reviser',\n 'themePhrases',\n 'num_pages',\n 'text',\n 'vol_number',\n 'vol_type',\n 'court_name',\n 'department_name',\n 'text_legal_bases',\n 'thesis']",
    "crumbs": [
      "Data",
      "Raw & Instruct Datasets Analyses"
    ]
  },
  {
    "objectID": "Data/dataset_description.html#dataset-description",
    "href": "Data/dataset_description.html#dataset-description",
    "title": "Raw & Instruct Datasets Analyses",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset consists of Polish Court judgements available at https://orzeczenia.ms.gov.pl/, containing full content of the judgements along with metadata sourced from official API and extracted from the judgement contents. Dataset was build in 3 stages, namely: 1. Data acquisition 2. Data preprocessing and extraction 3. Instruction dataset generation Following, we provide detailed description of each stage.\n\n1. Data acquisition\nFirst, we leveraged the official API to download all available judgements along with their metadata. The download procedure resulted in 414 148 documents, containing documents published no later than 2024-03-06. Among all documents, 408 423 (98.62%) contain content of the judgement, hence are usable for the further processing and final dataset.\nAcquired data consists of the following features:\n\n\n\n\n\n\n\n\nFeature name\nFeature description\nType\n\n\n\n\n_id\nunique identifier of the judgement\nstring\n\n\nsignature\nsignature of judgement (unique within court)\nstring\n\n\ndate\ndate of judgement\ndatetime (ISO format with timezone)\n\n\npublicationDate\ndate of judgement publication\ndatetime (ISO format with timezone)\n\n\nlastUpdate\ndate of last update of judgement\ndatetime (ISO format with timezone)\n\n\ncourtId\nsystem unique identifier of the court\nint\n\n\ndepartmentId\nsystem unique identifier of the court’s department\nint\n\n\ntype\ntype of the judgement (one of )\nstring\n\n\nexcerpt\nFirst 500 characters of the judgement\nstring or None\n\n\ncontent\nFull content of judgement as XML file\nstring or None\n\n\nchairman\nchairman judge name\nstring\n\n\ndecision\ndecision\nstring or None\n\n\njudges\nlist of judge names participating in the judgement\nlist[string]\n\n\nlegalBases\nlegal acts which are bases for the judgement (with references to online repository\nlist[dict[str, str]]\n\n\n\n\n\nData preprocessing\nFor further processing, we used only documents containing judgement content. During preprocessing, we extracted additional metadata from the content XML, and then converted XML to plain text. XML files contain tagged metadata which could be readily extracted with arbitrary XML parser. In particular, we were able to extend metadata fields described above by extracting following ones from XML:\n\n\n\n\n\n\n\n\nFeature name\nFeature description\nType\n\n\n\n\ntext_legal_bases\nlegal bases names found in text\nlist[dict[str, str]]\n\n\nnum_pages\nnumer of pages of the original document\nint\n\n\nvol_number\nvolume number\nint\n\n\nvol_type\nvolume type\nstring\n\n\ntext\nplain text extracted from content XML\nstring\n\n\n\nIn addition we mapped courtId and departmentId fields according to mapping acquired from https://orzeczenia.wroclaw.sa.gov.pl/indices. During this procedure we identified that some judgements have incorrect court or department identifiers, and decided to leave their names as empty values. In the aftermath, mapping resulted in the additional two columns: | Feature name | Feature description | Type | |—————–|—————————–|———-| | court_name | full name of the court | string | | department_name | full name of the court’s department | string |\nAll acquired and preprocessed data is stored in MongoDB dataset, and for further processing we performed dataset dump. The dumped dataset was used to create intruction dataset for information extraction. Also, we publish raw dataset dump called pl-court-judgments-raw.\n\ncourt_distribution = raw_ds.drop_nulls(subset=\"court_name\").select(\"court_name\").group_by(\"court_name\").len().sort(\"len\", descending=True).collect().to_pandas()\nax = sns.histplot(data=court_distribution, x=\"len\", log_scale=True, kde=True)\nax.set(title=\"Distribution of judgments per court\", xlabel=\"#Judgements in single court\", ylabel=\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\n\njudgements_per_year = raw_ds.select(\"date\").collect()[\"date\"].str.split(\" \").list.get(0).str.to_date().dt.year().value_counts().sort(\"date\").to_pandas()\njudgements_per_year = judgements_per_year[judgements_per_year[\"date\"] &lt; 2024]\n\n_, ax = plt.subplots(1, 1, figsize=(10, 5))\nax = sns.pointplot(data=judgements_per_year, x=\"date\", y=\"count\", linestyles=\"--\", ax=ax)\nax.set(xlabel=\"Year\", ylabel=\"Number of Judgements\", title=\"Yearly Number of Judgements\", yscale=\"log\")\nplt.xticks(rotation=90)\nplt.show()\n\n\n\n\n\n\n\n\n\ntypes = raw_ds.fill_null(value=\"&lt;null&gt;\").select(\"type\").group_by(\"type\").len().sort(\"len\", descending=True).collect().to_pandas()\n\n_, ax = plt.subplots(1, 1, figsize=(8, 8))\nax = sns.barplot(data=types, x=\"len\", y=\"type\", errorbar=None, ax=ax)\nax.set(xlabel=\"Count\", ylabel=\"Type\", title=\"Judgement types cardinality\", xscale=\"log\")\nplt.show()\n\n\n\n\n\n\n\n\n\nnum_judges = raw_ds.with_columns([pl.col(\"judges\").list.len().alias(\"num_judges\")]).select(\"num_judges\").sort(\"num_judges\").collect().to_pandas()\nax = sns.histplot(data=num_judges, x=\"num_judges\", bins=num_judges[\"num_judges\"].nunique())\nax.set(xlabel=\"#Judges per judgement\", ylabel=\"Count\", yscale=\"log\", title=\"#Judges per single judgement\")\nplt.show()\n\n\n\n\n\n\n\n\n\nnum_lb = raw_ds.with_columns([pl.col(\"legalBases\").list.len().alias(\"num_lb\")]).select(\"num_lb\").sort(\"num_lb\").collect().to_pandas()\nax = sns.histplot(data=num_lb, x=\"num_lb\", bins=num_lb[\"num_lb\"].nunique())\nax.set(xlabel=\"#Legal bases\", ylabel=\"Count\", yscale=\"log\", title=\"#Legal bases per judgement\")\nplt.show()\n\n\n\n\n\n\n\n\n\nraw_text_ds = load_dataset(\"parquet\", data_dir=\"../../data/datasets/pl/raw/\", columns=[\"_id\", \"text\"])\nraw_text_ds = raw_text_ds.filter(lambda x: x[\"text\"] is not None)\n\n\n\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n\ndef tokenize(batch: dict[str, list]) -&gt; list[int]: \n    tokenized = tokenizer(batch[\"text\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n    return {\"length\": tokenized[\"length\"]}\n\nraw_text_ds = raw_text_ds.map(tokenize, batched=True, batch_size=16, remove_columns=[\"text\"], num_proc=20)\nraw_text_ds\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['_id', 'length'],\n        num_rows: 408423\n    })\n})\n\n\n\njudgement_len = raw_text_ds[\"train\"].to_pandas()\n\nax = sns.histplot(data=judgement_len, x=\"length\", bins=50)\nax.set(xlabel=\"#Tokens\", ylabel=\"Count\", title=\"#Tokens distribution in judgements (llama-3 tokenizer)\", yscale=\"log\")\nax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x/1_000)}k'))\nplt.show()\n\n\n\n\n\n\n\n\n\nper_type_tokens = raw_ds.fill_null(value=\"&lt;null&gt;\").select([\"_id\", \"type\"]).collect().to_pandas().set_index(\"_id\").join(judgement_len.set_index(\"_id\"))\n\n_, ax = plt.subplots(1, 1, figsize=(10, 10))\nax = sns.boxenplot(data=per_type_tokens, y=\"type\", x=\"length\")\nax.set(xscale=\"log\", title=\"Judgement token count per type\", xlabel=\"#Tokens\", ylabel=\"Type\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInstruction dataset creation\nIn order to verify and fine-tune Large Language Models in task of automated information extraction from judgements, we built instruction dataset as follows. First, we identified information from metadata which is contained in text of the judgement. Therefore, the following fields were selected for extraction as targets: * date * judges * recorder * signature * court_name * department_name * legal_bases\nIn order to ensure high quality of the dataset, we performed filtering procedure, as described below.\n\nData filtering\n\nRemoval of judgements with missing values in targets - if any of the target field has missing value, entire judgement is discarded (information might still be contained in judgement text, and in such case the targets would be incorrect)\nCleaning judges field - in some examples, names of judges were concatenated into single name instead of being list of names, so we split them based on conjunction\nRemoving examples wherein targets are not in text - due to inherent errors in acquired data, some targets might be mistyped, hence we filter them out\n\nData cleaning removes 173297 examples, and dataset consists of 240851.\n\n\nGenerating instructions\nAfter cleaning we generate instructions for information extraction. Specifically, we define same prompt for each document, as follows:\nYou are extracting information from the Polish court judgments.\nExtract specified values strictly from the provided judgement. If information is not provided in the judgement, leave the field with null value.\nPlease return the response in the identical YAML format:\n'''yaml\ncourt_name: \"&lt;nazwa sądu, string containing the full name of the court&gt;\"\ndate: &lt;data, date in format YYYY-MM-DD&gt;\ndepartment_name: \"&lt;nazwa wydziału, string containing the full name of the court's department&gt;\"\njudges: \"&lt;sędziowie, list of judge full names&gt;\"\nlegal_bases: &lt;podstawy prawne, list of strings containing legal bases (legal regulations)&gt;\nrecorder: &lt;protokolant, string containing the name of the recorder&gt;\nsignature: &lt;sygnatura, string contraining the signature of the judgment&gt;\n'''\n=====\n{context}\n======\nwhere {context} is replaced by text of each judgement. We highlight that judements are in Polish, hence to foster model responding in Polish, we provide name Polish names of the field in the prompt.",
    "crumbs": [
      "Data",
      "Raw & Instruct Datasets Analyses"
    ]
  },
  {
    "objectID": "Data/dataset_description.html#analysis",
    "href": "Data/dataset_description.html#analysis",
    "title": "Raw & Instruct Datasets Analyses",
    "section": "Analysis",
    "text": "Analysis\n\nfrom torch import le\n\n\ndef tokenize_and_comp_length_instruct_ds(batch: dict[str, list]) -&gt; dict[str, list]:\n    tokenized_ctx = tokenizer(batch[\"context\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n    tokenized_out = tokenizer(batch[\"output\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n\n    return {\"context_num_tokens\": tokenized_ctx[\"length\"], \"output_num_tokens\": tokenized_out[\"length\"]}\n\ninstruct_ds_tok = instruct_ds.map(tokenize_and_comp_length_instruct_ds, batched=True, batch_size=32, remove_columns=[\"prompt\", \"context\", \"output\"], num_proc=20)\ninstruct_ds_tok = pd.concat([instruct_ds_tok[\"train\"].to_pandas(), instruct_ds_tok[\"test\"].to_pandas()], axis=0, keys=[\"train\", \"test\"]).reset_index(level=0).rename(columns={\"level_0\": \"split\"})\ninstruct_ds_tok.head()\n\n\n\n\n\n\n\n\nsplit\n_id\ncontext_num_tokens\noutput_num_tokens\n\n\n\n\n0\ntrain\n150515100001006_II_K_000220_2017_Uz_2017-10-03...\n2371\n134\n\n\n1\ntrain\n152500000001521_III_AUa_000581_2013_Uz_2014-02...\n5984\n233\n\n\n2\ntrain\n155500000000503_I_ACa_000098_2016_Uz_2016-06-1...\n21328\n128\n\n\n3\ntrain\n150510000000503_I_Ca_000018_2016_Uz_2016-01-28...\n369\n97\n\n\n4\ntrain\n150515300001006_II_K_000438_2018_Uz_2018-11-14...\n6918\n143\n\n\n\n\n\n\n\n\nprint(f\"0.95 quantile of maximum output: {instruct_ds_tok['output_num_tokens'].quantile(0.95)}\")\n\n0.95 quantile of maximum output: 295.0\n\n\n\ntok_melt = instruct_ds_tok.melt(id_vars=[\"split\"], value_vars=[\"context_num_tokens\", \"output_num_tokens\"], var_name=\"Text\", value_name=\"#Tokens\")\ntok_melt[\"Text\"] = tok_melt[\"Text\"].map({\"context_num_tokens\": \"Context\", \"output_num_tokens\": \"Output\"})\n\ng = sns.displot(data=tok_melt, x=\"#Tokens\", col=\"Text\", hue=\"split\", kind=\"kde\", fill=True, log_scale=True, common_norm=False, facet_kws=dict(sharex=False, sharey=False))\ng.figure.suptitle(\"Distribution of #Tokens (llama-3 tokenizer) in Context and Output in instruct dataset\")\ng.figure.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n_, ax = plt.subplots(1, 1, figsize=(10, 10))\nax = sns.countplot(data=per_type_tokens.join(instruct_ds_tok.set_index(\"_id\"), how=\"right\"), y=\"type\", hue=\"split\")\nax.set(xscale=\"log\", title=\"Distribution of types in dataset splits\", xlabel=\"Count\", ylabel=\"Type\")\nplt.show()",
    "crumbs": [
      "Data",
      "Raw & Instruct Datasets Analyses"
    ]
  },
  {
    "objectID": "Data/prepare_instruction_dataset_for_ir.html",
    "href": "Data/prepare_instruction_dataset_for_ir.html",
    "title": "Schema-based information retrieval from judgements",
    "section": "",
    "text": "from loguru import logger\n\nimport mlflow\n\nfrom juddges.prompts.information_extraction import (\n    prepare_information_extraction_chain,\n    EXAMPLE_SCHEMA,\n)\nfrom juddges.settings import prepare_langchain_cache, prepare_mlflow\nfrom juddges.data.pl_court_api import PolishCourtAPI\n\n\nfrom dotenv import load_dotenv\n\nload_dotenv(\"../../.env\")\n\nTrue\n\n\n\nprepare_langchain_cache()\nprepare_mlflow()\n\n\nlogger.add(level=\"INFO\", sink=\"../../logs/ir_judgments.log\")\n\n1\n\n\n\nLLM_NAME = \"gpt-4-0125-preview\"\nPROMPT_VERSION = \"initial-ir\"\nLANGUAGE = \"Polish\"\n\n\nmlflow.start_run(run_name=f\"{PROMPT_VERSION}-{LLM_NAME}\")\n\n&lt;ActiveRun: &gt;\n\n\n\napi = PolishCourtAPI()\n\n\njudgement = api.get_content(id=\"155000000001006_II_AKa_000334_2019_Uz_2020-02-06_001\")\n\n\njudgement\n\n{'content': '&lt;?xml version=\\'1.0\\' encoding=\\'UTF-8\\'?&gt;\\n&lt;xPart xPublisherFullName=\"Anna Turek\" xPublisher=\"anna.turek\" xEditorFullName=\"Wiktoria Dąbrowicz\" xEditor=\"wiktoria.dabrowicz\" xVersion=\"1.0\" xLang=\"PL\" xFromPg=\"1\" xToPage=\"2\" xFlag=\"published\" xVolType=\"15/500000/0001006/AKa\" xYear=\"2019\" xVolNmbr=\"000334\" xDocType=\"Uz\" xml:space=\"preserve\"&gt;\\n  &lt;xName&gt;Wyrok&lt;/xName&gt;\\n  &lt;xBlock&gt;\\n    &lt;xText xALIGNx=\"left\"&gt;\\n      &lt;xBx&gt;Sygn. akt II AKa 334/19&lt;/xBx&gt;&lt;/xText&gt;\\n    &lt;xText/&gt;\\n    &lt;xUnit xBold=\"true\" xIsTitle=\"true\" xType=\"part\"&gt;\\n      &lt;xName&gt;WYROK&lt;/xName&gt;\\n      &lt;xTitle&gt;W IMIENIU RZECZYPOSPOLITEJ POLSKIEJ&lt;/xTitle&gt;\\n      &lt;xText xALIGNx=\"right\"&gt;Dnia 6 lutego 2020 r.&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;Sąd Apelacyjny we Wrocławiu II Wydział Karny w składzie:&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;Przewodniczący: sędzia SA Cezariusz Baćkowski&lt;/xText&gt;\\n      &lt;xText&gt;Sędziowie: SA Piotr Kaczmarek (spr.)&lt;/xText&gt;\\n      &lt;xText&gt;SA Robert Zdych&lt;/xText&gt;\\n      &lt;xText&gt;Protokolant: Wiktoria Dąbrowicz&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;przy udziale prokuratora Prokuratury &lt;xAnon&gt; (...)&lt;/xAnon&gt; we &lt;xAnon&gt;W.&lt;/xAnon&gt; Zbigniewa Jaworskiego&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;po rozpoznaniu w dniu 20 grudnia 2019 r., 31 stycznia 2020 r. i 6 lutego 2020 r.&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;sprawy:&lt;xBRx/&gt;&lt;xAnon&gt;A. D.&lt;/xAnon&gt; (&lt;xAnon&gt;D.&lt;/xAnon&gt;)&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;oskarżonego z &lt;xLexLink xArt=\"art. 258;art. 258 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 258 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 55;art. 55 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 55 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 56;art. 56 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 56 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 18;art. 18 § 3\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 18 § 3 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 299;art. 299 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 299 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;&lt;xAnon&gt;R. M.&lt;/xAnon&gt; &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;oskarżonego z &lt;xLexLink xArt=\"art. 258;art. 258 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 258 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 55;art. 55 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 55 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 56;art. 56 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 56 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 299;art. 299 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 299 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;&lt;xAnon&gt;E. L.&lt;/xAnon&gt; (&lt;xAnon&gt;L.&lt;/xAnon&gt;)&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;oskarżonej z &lt;xLexLink xArt=\"art. 299;art. 299 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 299 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;&lt;xAnon&gt;R. P.&lt;/xAnon&gt; &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;oskarżonego z &lt;xLexLink xArt=\"art. 56;art. 56 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 56 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;\\n  &lt;xBx&gt;\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    &lt;xAnon&gt;L. L.&lt;/xAnon&gt; (&lt;xAnon&gt;L.&lt;/xAnon&gt;)&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;oskarżonego z &lt;xLexLink xArt=\"art. 258;art. 258 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 258 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 18;art. 18 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 18 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 55;art. 55 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 55 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 64;art. 64 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 64 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 18;art. 18 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 18 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 56;art. 56 ust. 3\" xIsapId=\"WDU20051791485\" xTitle=\"Ustawa z dnia 29 lipca 2005 r. o przeciwdziałaniu narkomanii\" xAddress=\"Dz. U. z 2005 r. Nr 179, poz. 1485\"&gt;art. 56 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 64;art. 64 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 64 § 1 k.k.&lt;/xLexLink&gt;, z &lt;xLexLink xArt=\"art. 18;art. 18 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 18 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 299;art. 299 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 299 § 1 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 12\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 12 k.k.&lt;/xLexLink&gt; w zw. z &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;na skutek apelacji wniesionej przez oskarżonych&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;od wyroku Sądu Okręgowego w Świdnicy &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;z dnia 5 kwietnia 2019 r., sygn. akt III K 52/17&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;I&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;zmienia zaskarżony wyrok: &lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;1&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;co do oskarżonego  \\n            &lt;xUx&gt;&lt;xAnon&gt;R. M.&lt;/xAnon&gt;&lt;/xUx&gt;\\n            w ten sposób, że:&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;a&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uniewinnia oskarżonego od przestępstwa przypisanego w punkcie I, stwierdzając, że utraciło moc orzeczenie o karze łącznej pozbawienia wolności zawarte w punkcie VII,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;b&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;w przestępstwach przypisanych w punkcie II i IV pomija ustalenie o działaniu w ramach zorganizowanej grupy przestępczej, w miejsce ustalenia o przekazaniu &lt;xAnon&gt;R. P.&lt;/xAnon&gt;, przyjmuje ustalenie o przekazaniu innej osobie oraz w kwalifikacji prawnej pomija &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;c&lt;/xName&gt;\\n        &lt;xText&gt;\\n  &lt;xBx&gt;\\n    \\n    \\n    w przestępstwie przypisanym w punkcie V pomija ustalenie o działaniu w ramach zorganizowanej grupy przestępczej, w miejsce ustalenia o przekazaniu &lt;xAnon&gt;E. L.&lt;/xAnon&gt; przyjmuje przekazanie innej osobie, w miejsce ustalenia o działaniu wspólnie i w porozumieniu z &lt;xAnon&gt;L. L.&lt;/xAnon&gt; przyjmuje ustalenie o działaniu wspólnie i w porozumieniu z inną osobą oraz w kwalifikacji prawnej pomija &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt; ,&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;d&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uchyla orzeczenie o przepadku równowartości części korzyści zawarte w punkcie VI;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;2&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;co do oskarżonego  \\n            &lt;xUx&gt;&lt;xAnon&gt;A. D.&lt;/xAnon&gt;&lt;/xUx&gt;\\n            w ten sposób, że:&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;a&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uniewinnia oskarżonego od przestępstwa przypisanego w punkcie VIII, stwierdzając, że utraciło moc orzeczenie o karze łącznej pozbawienia wolności zawarte w punkcie XIV,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;b&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;w przestępstwach przypisanych w punkcie IX i XI pomija ustalenie o działaniu w ramach zorganizowanej grupy przestępczej, w miejsce ustalenia o przekazaniu &lt;xAnon&gt;R. P.&lt;/xAnon&gt;, przyjmuje ustalenie o przekazaniu innej osobie oraz w kwalifikacji prawnej pomija &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;c&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uniewinnia oskarżonego od przestępstwa przypisanego w punkcie XII, stwierdzając, że straciło moc orzeczenie o przepadku równowartości części korzyści zawarte w punkcie XIV;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;3&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;co do oskarżonego  \\n            &lt;xUx&gt;&lt;xAnon&gt;R. P.&lt;/xAnon&gt;&lt;/xUx&gt;\\n            w ten sposób, że uniewinnia oskarżonego od przestępstwa przypisanego w punkcie XV;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;4&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;co do oskarżonej  \\n            &lt;xUx&gt;&lt;xAnon&gt;E. L.&lt;/xAnon&gt;&lt;/xUx&gt;\\n            w ten sposób, że uniewinnia oskarżoną od przestępstwa przypisanego w punkcie XVII&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;5&lt;/xName&gt;\\n        &lt;xText&gt;\\n  &lt;xBx&gt;\\n    co do oskarżonego  \\n            &lt;xUx&gt;\\n      &lt;xAnon&gt;L. L.&lt;/xAnon&gt;&lt;/xUx&gt;\\n            w ten sposób, że:&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;a&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uniewinnia oskarżonego od przestępstwa przypisanego w punkcie XIX, stwierdzając, że utraciło moc orzeczenie o karze łącznej pozbawienia wolności zawarte w punkcie XXV,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;b&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;w przestępstwach przypisanych w punkcie XX i XXII pomija ustalenie o działaniu w ramach zorganizowanej grupy przestępczej, w miejsce ustalenia o ustalaniu terminów i okoliczności odbioru przez &lt;xAnon&gt;R. P.&lt;/xAnon&gt;, przyjmuje ustalenie o ustalaniu terminów i okoliczności odbioru przez inną osobę oraz w kwalifikacji prawnej pomija &lt;xLexLink xArt=\"art. 65;art. 65 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 65 § 1 k.k.&lt;/xLexLink&gt;,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\")\"&gt;c&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;uniewinnia oskarżonego od przestępstwa przypisanego w punkcie XXIII, stwierdzając, że straciło moc orzeczenie o przepadku równowartości części korzyści zawarte w punkcie XXIV,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;II&lt;/xName&gt;\\n        &lt;xText&gt;\\n  &lt;xBx&gt;\\n    w pozostałym zakresie zaskarżony wyrok co do oskarżonych &lt;xAnon&gt;R. M.&lt;/xAnon&gt;, &lt;xAnon&gt;A. D.&lt;/xAnon&gt; i &lt;xAnon&gt;L. L.&lt;/xAnon&gt; utrzymuje w mocy;&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;III&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;na podstawie &lt;xLexLink xArt=\"art. 85;art. 85 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 85 § 1 k.k.&lt;/xLexLink&gt; i &lt;xLexLink xArt=\"art. 86;art. 86 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 86 § 1 k.k.&lt;/xLexLink&gt; łączy kary pozbawienia wolności wymierzone oskarżonym:&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xText&gt;&lt;xBx&gt;- &lt;xAnon&gt;R. M.&lt;/xAnon&gt; w punkcie II i IV i wymierza karę łączną 4 (czterech) lat i 6 (sześciu) miesięcy pozbawienia wolności,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;- &lt;xAnon&gt;A. D.&lt;/xAnon&gt; w punkcie IX i XI i wymierza karę łączną 4 (czterech) lat pozbawienia wolności,&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;\\n  &lt;xBx&gt;\\n    - &lt;xAnon&gt;L. L.&lt;/xAnon&gt; w punkcie XX i XXII i wymierza karę łączną 5 (pięciu) lat i 6 (sześciu) miesięcy pozbawienia wolności;&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;IV&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;na podstawie &lt;xLexLink xArt=\"art. 63;art. 63 § 1\" xIsapId=\"WDU19970880553\" xTitle=\"Ustawa z dnia 6 czerwca 1997 r. - Kodeks karny\" xAddress=\"Dz. U. z 1997 r. Nr 88, poz. 553\"&gt;art. 63 § 1 k.k.&lt;/xLexLink&gt; na poczet orzeczonych kar pozbawienia wolności zalicza:&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xText&gt;&lt;xBx&gt;- oskarżonemu &lt;xAnon&gt;R. M.&lt;/xAnon&gt; okresy zatrzymania od 1 grudnia 2015 roku do 3 grudnia 2015 roku oraz od 25 stycznia 2017 roku do 26 stycznia 2017 roku;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;&lt;xBx&gt;- oskarżonemu &lt;xAnon&gt;A. D.&lt;/xAnon&gt; okresy zatrzymania i tymczasowego aresztowania od 20 czerwca 2015 roku do 12 listopada 2015 roku oraz od 25 stycznia 2017 roku do 26 stycznia 2017 roku;&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;xText&gt;\\n  &lt;xBx&gt;\\n    - oskarżonemu &lt;xAnon&gt;L. L.&lt;/xAnon&gt; okres tymczasowego aresztowania w sprawie od 26 stycznia 2019 roku do 5 kwietnia 2019 roku;&lt;/xBx&gt;\\n&lt;/xText&gt;\\n      &lt;xUnit xIsTitle=\"false\" xType=\"none\"&gt;\\n        &lt;xName xSffx=\".\"&gt;V&lt;/xName&gt;\\n        &lt;xText&gt;&lt;xBx&gt;wydatkami związanymi z postępowaniem, w części której nastąpiło uniewinnienie obciąża Skarb Państwa, w pozostałym zakresie zwalniając oskarżonych od kosztów za postępowanie odwoławcze.&lt;/xBx&gt;&lt;/xText&gt;\\n      &lt;/xUnit&gt;\\n      &lt;xRows&gt;\\n        &lt;xCOLGROUPx&gt;\\n          &lt;xCOLx xWIDTHx=\"240\"/&gt;\\n          &lt;xCOLx xWIDTHx=\"239\"/&gt;\\n          &lt;xCOLx xWIDTHx=\"237\"/&gt;\\n        &lt;/xCOLGROUPx&gt;\\n        &lt;xRow&gt;\\n          &lt;xClmn xALIGNx=\"left\"&gt;\\n            &lt;xText xALIGNx=\"center\"&gt;Piotr Kaczmarek&lt;/xText&gt;\\n          &lt;/xClmn&gt;\\n          &lt;xClmn xALIGNx=\"left\"&gt;\\n            &lt;xText xALIGNx=\"center\"&gt;Cezariusz Baćkowski&lt;/xText&gt;\\n          &lt;/xClmn&gt;\\n          &lt;xClmn xALIGNx=\"left\"&gt;\\n            &lt;xText xALIGNx=\"center\"&gt;Robert Zdych&lt;/xText&gt;\\n          &lt;/xClmn&gt;\\n        &lt;/xRow&gt;\\n      &lt;/xRows&gt;\\n    &lt;/xUnit&gt;\\n  &lt;/xBlock&gt;\\n&lt;/xPart&gt;\\n'}\n\n\n\nprint(EXAMPLE_SCHEMA)\n\nverdict_date: date as ISO 8601\nverdict: string, text representing verdict of the judgement\nverdict_summary: string, short summary of the verdict\nverdict_id: string\ncourt: string\nparties: string\nappeal_against: string\nfirst_trial: boolean\ndrug_offence: boolean\nchild_offence: boolean\noffence_seriousness: boolean\nverdict_tags: List[string]\n\n\n\nchain = prepare_information_extraction_chain()\n\n\nlogged_model = mlflow.langchain.log_model(chain, \"langchain_model\")\n\n2024/04/12 12:20:42 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_e0svs4s/model, flavor: langchain). Fall back to return ['langchain==0.1.13', 'pydantic==2.7.0', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n\n\n\nmlflow.log_param(\"prompt_version\", PROMPT_VERSION)\nmlflow.log_param(\"llm_name\", LLM_NAME)\nmlflow.log_param(\"language\", LANGUAGE)\nmlflow.log_param(\"schema\", EXAMPLE_SCHEMA)\n\n'verdict_date: date as ISO 8601\\nverdict: string, text representing verdict of the judgement\\nverdict_summary: string, short summary of the verdict\\nverdict_id: string\\ncourt: string\\nparties: string\\nappeal_against: string\\nfirst_trial: boolean\\ndrug_offence: boolean\\nchild_offence: boolean\\noffence_seriousness: boolean\\nverdict_tags: List[string]'\n\n\n\nEXAMPLE_SCHEMA = \"\"\"\nRodzaj_przestepstwa_i_kwalifikacja_prawna: string\nDodatkowe_okolicznosci: {'recydywa': 'boolean', 'w_zwiazku_z_art_207_kk_znecanie_sie': 'boolean', 'zgwalcenie_maloletniego_zbiorowe_kazirodcze_ze_szczegolnym_okrucienstwem': 'boolean'}\nRodzaj_wyroku: string\nSankcja_karna: {'wyrok_w_zawieszeniu': 'boolean', 'skazujacy_na_kare_pobawienia_wolnosci_od_lat_2_do_lat_3': 'boolean', 'skazujacy_na_kare_pobawienia_wolnosci_od_lat_3': 'boolean', 'kara_25_lat_pobawienia_wolnosci': 'boolean'}\nSrodki_kompensacyjne: {'czy_jest': 'boolean', 'jaka_kwota': 'integer'}\nSrodki_karne: {'jakie': 'string'}\nOkolicznosci_zwiazane_z_opisem_czynu: {'stosowanie_przemocy': 'boolean', 'grozby_bezprawnej': 'boolean', 'podstepu': 'boolean', 'wykorzystanie_bezradnosci': 'boolean', 'znajdowanie_sie_pod_wplywem_alkoholu': 'boolean', 'podanie_GHB_innej_podobnie_dzialajacej_substancji': 'boolean'}\n\"\"\"\n\n\nretrieved_informations = chain.invoke(\n    {\"LANGUAGE\": LANGUAGE, \"TEXT\": judgement, \"SCHEMA\": EXAMPLE_SCHEMA}\n)\n\n\nretrieved_informations\n\n{'Rodzaj_przestepstwa_i_kwalifikacja_prawna': 'art. 258 § 1 k.k., art. 55 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii, art. 12 k.k., art. 65 § 1 k.k., art. 56 ust. 3 ustawy z dnia 29 lipca 2005 roku o przeciwdziałaniu narkomanii, art. 299 § 1 k.k., art. 18 § 3 k.k.',\n 'Dodatkowe_okolicznosci': {'recydywa': False,\n  'w_zwiazku_z_art_207_kk_znecanie_sie': False,\n  'zgwalcenie_maloletniego_zbiorowe_kazirodcze_ze_szczegolnym_okrucienstwem': False},\n 'Rodzaj_wyroku': 'zmiana wyroku; uniewinnienie od niektórych przestępstw; utrzymanie w mocy pozostałej części wyroku',\n 'Sankcja_karna': {'wyrok_w_zawieszeniu': False,\n  'skazujacy_na_kare_pobawienia_wolnosci_od_lat_2_do_lat_3': False,\n  'skazujacy_na_kare_pobawienia_wolnosci_od_lat_3': True,\n  'kara_25_lat_pobawienia_wolnosci': False},\n 'Srodki_kompensacyjne': {'czy_jest': False, 'jaka_kwota': 0},\n 'Srodki_karne': {'jakie': ''},\n 'Okolicznosci_zwiazane_z_opisem_czynu': {'stosowanie_przemocy': False,\n  'grozby_bezprawnej': False,\n  'podstepu': False,\n  'wykorzystanie_bezradnosci': False,\n  'znajdowanie_sie_pod_wplywem_alkoholu': False,\n  'podanie_GHB_innej_podobnie_dzialajacej_substancji': False}}\n\n\n\nfrom juddges.data.models import get_mongo_collection\n\njudgements_collection = get_mongo_collection(\"judgements\")\n\n\n# search for mongo documents with empty text field, index named `text_text`\njudgements = list(\n    judgements_collection.find({\"$text\": {\"$search\": \"przestepstwo seksualne\"}}).limit(10)\n)\n\n\n# judgements = list(judgements_collection.find(filter={}).limit(100))\n\n\nlen(judgements)\n\n10\n\n\nEstimate price of prompt with judgements text for 100 sample (is USD)\n\nfrom juddges.settings import num_tokens_from_string, LLM_TO_PRICE_INPUT\n\nsum(\n    [\n        LLM_TO_PRICE_INPUT[LLM_NAME] * num_tokens_from_string(judgement[\"text\"])\n        for judgement in judgements\n    ]\n)\n\n1.53363\n\n\n\nprint(judgements[0][\"text\"])\n\nWYROK ŁĄCZNY\n\nW IMIENIU\n\nRZECZYPOSPOLITEJ POLSKIEJ\n\nDnia 07 maja 2014 roku.\n\nSąd Okręgowy w Poznaniu w III Wydziale Karnym w składzie:\n\nPrzewodnicząca: SSO Katarzyna Wolff\nProtokolant: Patrycja Rataj\nprzy udziale Prokuratora Wojskowej Prokuratury Okręgowej w Poznaniu Agnieszka Hildebrandt\npo rozpoznaniu dnia 07 maja 2014r\n\nsprawy:\n\nA. W.,synaR.iE.z domuS.,urodzonego (...)wP.\n\nskazanego prawomocnymi wyrokami:\n\nI\nSądu Rejonowego w Poznaniu z dnia 17 czerwca 1999 roku sygn. aktVK 667/99za przestępstwo zart. 279§1kkpopełnione w dniu 24.12.1998r na karę 2 lat pozbawienia wolności z warunkowym zawieszeniem na okres 5 lat próby oraz grzywnę w wysokości 100 stawek dziennych po 20 złotych, po czym postanowieniem Sądu Rejonowego w Poznaniu zarządzono wykonanie kary pozbawienia wolności\n\nII\nSądu Rejonowego w Wałczu z dnia 24.09.2002r sygn. aktIIK 468/02za przestępstwo zart. 209 § 1 kkpopełnione w okresie od 20.03.2001r do lutego 2002r na karę 10 miesięcy ograniczenia wolności polegającej na wykonywaniu nieodpłatnej dozorowanej pracy na cel społeczny w wymiarze 20 godzin w stosunku miesięcznym, po czym postanowieniem Sądu Rejonowego w Wałczu zamieniono tę karę na karę grzywny\n\nIII\nSądu Rejonowego Poznań Stare Miasto w Poznaniu z dnia 21.05.2011 r w sprawie sygn. IIIK 383/08za:\n\n- przestępstwo zart. 258§1 i 3 kk78§1 kkpopełnione w okresie od stycznia 2002r do października 2004 r na karę 2 miesięcy pozbawienia wolności.\n- przestępstwo zart. 298§ 1kkiart. 286§1 kkw zw. zart. 11§2 kkiart. 12 kkpopełnione w okresie od 7 maja 2001 r do 21 września 2001r na karę 1 roku pozbawienia wolności oraz 20 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 238 kkw zw. zart. 233§ 1 kkiart. 11§2 kkpopełnione w dniu 28 maja 2001r na karę 8 miesięcy pozbawienia wolności\n- przestępstwo zart. 286§1 kkpopełnione w okresie od 31 maja 2001r do 16 lipca 2001r na karę 1 roku pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 18§2 kkw zw. zart. 238 kkw zw. zart. 233§ 1 kkiart. 11§2 kkpopełnione w marcu 2002r na karę 8 miesięcy pozbawienia wolności\n- przestępstwo zart. 286§1 kkpopełnione w okresie od 4 marca 2002 r do 10 maja 2002r na karę 1 roku pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 18§2 kkw zw. zart. 238 kkw zw. zart. 233§ 1 kkiart. 11§2 kkpopełnione w marcu 2002r na karę 8 miesięcy pozbawienia wolności\n- przestępstwo zart. 13§1 kkw zw. zart. 286§1 kkpopełnione w okresie od 4 marca 2002r do 30 sierpnia 2002r na karę 10 miesięcy pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 270§ 1 kkpopełnione 11.09.2002r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 270§ 1 kkpopełnione w lutym 2003r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 270§ 1 kkpopełnione w 2003r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 270§ 1 kkpopełnione w listopadzie 2003 r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§2 kkw zw. zart. 272 kkpopełnione w listopadzie 2003 r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 297§1 kkw zw zart. 286§1 kkw zw zart. 11§2 kkpopełnione 15.01.2004r na karę 1 roku pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w styczniu 2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkw zw zart. 270§ 1 kkw zw. zart. 11§2 kkpopełnione w lutym 2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 270§1 kkpopełnione w dniu 26.04.2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 291§ 1kkpopełnione w okresie od 1 lipca 2004 do 19 lipca 2004r na karę 8 miesięcy pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w lipcu 2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w lipcu 2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 286§1 kkpopełnione w okresie od 17.08.2004r do 25.09.2004r na karę 10 miesięcy pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 284§2kk kkpopełnione 17.08.2004r na karę 1 roku pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 233§1 kkw zw. zart. 238 kkw zw. zart. 11§2 kkpopełnione w styczniu 2004r na karę 8 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w październiku 2004 r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w listopadzie 2004r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 291§1 kkpopełnione w okresie od 23.12.2004r do 13.01.2005r na karę 10 miesięcy pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 291§1kkpopełnione w okresie od 2.02.2005r do 23.05.2005r na karę 8 miesięcy pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 306 kkpopełnione w okresie od 02.02.2005r do 23.05.2005r na karę 8 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 272 kkpopełnione w czerwcu 2005r na karę 6 miesięcy pozbawienia wolności\n- przestępstwo zart. 18§ 2 kkw zw. zart. 238 kkw zw zart. 233§1 kkw zw. zart. 11§2kkpopełnione 05.07.2005r na karę 8 miesięcy pozbawienia wolności\n- przestępstwoart. 286§1 kkpopełnione w okresie od 06.07.2005 r do 24.08.2005r na karę 1 roku pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n- przestępstwo zart. 286§1kkpopełnione w okresie od 12.09.2005r do 05.11.2005r na karę 1 roku pozbawienia wolności i 10 stawek dziennych grzywny po 100 złotych\n\nktóre połączono wymierzając karę łączną 6 lat pozbawienia wolności i 150 stawek dziennych grzywny po 100 złotych, przy czym wyrokiem Sądu Okręgowego w Poznaniu z dnia 07 lipca 2011 r w sprawie IV AKa 178/11 złagodzono orzeczoną karę łączna pozbawienia wolności do4 lat,a karę łączną grzywny do60 stawek dziennych po 100 złotych\n\nIV\nSądu Rejonowego Poznań Grunwald i Jeżyce w Poznaniu z dnia 20.11.2012r sygn. akt\n    III K 536/12za przestępstwo zart. 270 § 1 kkw zw. zart. 12 kkpopełnione w nieokreślonym czasie na karę 8 miesięcy pozbawienia wolności, za czyn zart. 18§2 kkw zw zart. 233§1 kkpopełniony w dniu 10.10.2005 r na karę 10 miesięcy pozbawienia wolności, za czyn zart. 18§2 kkw zw zart. 233§1 kkpopełniony 10.10.2005r na karę 10 miesięcy pozbawienia wolności, za czyn zart. 245 kkpopełniony 10.11.2005r na karę 1 roku pozbawienia wolności, za czyn zart. 286§1 kkpopełniony w okresie od 15.07.2004r do 31.08.2004r na karę 1 roku i 6 miesięcy pozbawienia wolności, które połączono wymierzając karę łączną 1 roku i 6 miesięcy pozbawienia wolności\n\nV\nSądu Okręgowego w Poznaniu z dnia 13.12.2012r w sprawie sygn.III K 49/2012za przestępstwo zart. 13§1 kkw zw. zart. 286§1 kkpopełnione w okresie od stycznia 2002 r do września 2004 na karę 3 lat pozbawienia wolności i 100 stawek dziennych grzywny po 100 złotych\n\nVI\nSądu Rejonowego Poznań Grunwald i Jeżyce w Poznaniu z dnia 31.01.2012r r w sprawie sygn.\n    III K 640/08za:\n\n- czyn zart. 297§1 kkiart. 286§1 kkiart. 270§1 kkw zw zart. 11§2 kkpopełniony w dniu 29.11.2004r na karę 1 roku pozbawienia wolności i 80 stawek dziennych grzywny po 20 złotych\n- czyn zart. 297§1 kkiart. 286§1 kkiart. 273 kkw zw zart. 271§1 kkw zw zart. 11§2 kkpopełniony w dniu 26.01.2005r na karę 1 roku i 2 miesięcy pozbawienia wolności i 100 stawek dziennych grzywny po 20 złotych\n- czyny zart. 286§1 kkiart. 13§1 kkw zw. zart. 286§1 kkw zw. zart. 91§1 kkpopełnione w okresach od 25.05.2005 r do 23.06.2005r, od 08.07.2005r do 15.11.2005r, od 28.11.2005r do 13.12.2005r, od 20.01.2006r do 09.03.2006r na karę 1 roku i 6 miesięcy pozbawienia wolności i 150 stawek dziennych grzywny po 20 złotych\n- czyny zart. 297§1 kkiart. 286§1 kkiart. 273w zw zart. 270§1 kkw zw. zart. 11§2 kkpopełnione w dniach 30.06.2005r i 18.07.2005r na karę 1 roku i 4 miesięcy pozbawienia wolności i 130 stawek dziennych grzywny po 20 złotych,\nktóre połączono wymierzając karę łączną 2 lat i 10 miesięcy pozbawienia wolności oraz 300 stawek dziennych grzywny po 20 złotych\n\n1\nRozwiązuje węzeł kar łącznych orzeczonych wyrokami w sprawach sygn. III K 383/08 Sądu Rejonowego Poznań Stare Miasto w Poznaniu, III K 536/12 i III K 640/08 Sądu Rejonowego Poznań Grunwald i Jeżyce w Poznaniu\n\n2\nNa podstawieart. 569 § 1i 2 kpk,art. 85 kkiart. 86 § 1i 2 kkłączy kary pozbawienia wolności i grzywny orzeczone wyrokami wskazanymi wyżej w punktach III- VI i wymierza skazanemuA. W.karę łączną w wymiarze4 (czterech) lat i 6 (sześciu) miesięcy pozbawienia wolności oraz 100 (stu) stawek dziennych grzywny po 100 (sto) złotych\n\n3\nNa podstawieart. 577 kpkna poczet kary łącznej pozbawienia wolności orzeczonej w punkcie 2. wyroku zalicza skazanemu okres rzeczywistego pozbawienia wolności w sprawie sygn. III K 383/08 Sądu Rejonowego Poznań Stare Miasto w Poznaniu od dnia 01.02.2006 r do 14.07.2006r i od 07.03.2012r do 07.05.2014r i nadal\n\n4\nW pozostałym zakresie wyżej wymienione wyroki podlegają odrębnemu wykonaniu.\n\n5\nNa podstawieart. 572 kpkumarza postępowania co do wydania wyroku łącznego w pozostałym zakresie\n\n6\nNa podstawie§ 14 ust 5 Rozporządzenia Ministra Sprawiedliwości z dnia 28.09.2002 r. w sprawie opłat za czynności adwokackie oraz ponoszenie przez Skarb Państwa kosztów nieopłaconej pomocy prawnej udzielonej z urzędu(Dz. U. z 2002 r., nr 163, poz. 1348 ze zm.) zasądza od Skarbu Państwa na rzecz adwokataB. M.kwotę 140, 40 złotych (w tym VAT) tytułem kosztów nieopłaconej pomocy prawnej udzielonej skazanemu z urzędu.\n\n7\nNa podstawieart. 624 § 1 kpkzwalnia skazanego od obowiązku zapłaty na rzecz Skarbu Państwa kosztów postępowania w całości, a na podstawieart. 6 ustawy z dnia 23 czerwca 1973 roku o opłatach w sprawach karnych(Dz. U. z 1983 roku, nr 49, poz. 223 ze zm.) nie wymierza skazanemu opłaty.\n\nSSO Katarzyna Wolff\n\n\n\n# save sample judgments\nimport pandas as pd\nfrom juddges.settings import SAMPLE_DATA_PATH\n\n\ndf = pd.DataFrame(judgements)\ndf.to_csv(SAMPLE_DATA_PATH / \"judgements-konfiskata-10-sample.csv\")\n\n\ndf.head(2)\n\n\n\n\n\n\n\n\n_id\nsignature\ndate\npublicationDate\nlastUpdate\ncourtId\ndepartmentId\ntype\nexcerpt\ncontent\n...\nlegalBases\npublisher\nrecorder\nreferences\nreviser\nthemePhrases\nnum_pages\ntext\nvol_number\nvol_type\n\n\n\n\n0\n153510000001506_III_K_000042_2014_Uz_2014-05-0...\nIII K 42/14\n2014-05-07 02:00:00.0 CEST\n2014-05-30 20:15:03.0 CEST\n2014-06-17 00:57:36.0 CEST\n15351000\n1506\nSENTENCE\nWYROK ŁĄCZNY W IMIENIU RZECZYPOSPOLITEJ POLSKI...\n&lt;?xml version='1.0' encoding='UTF-8'?&gt;\\n&lt;xPart...\n...\n[art. 85 i art. 86 § 1 i 2 kk]\nJustyna Grzegorek\nPatrycja Rataj\n[Ustawa z dnia 23 czerwca 1973 r. o opłatach w...\nAgnieszka Sikorska\n[Wyrok Łączny]\n4\nWYROK ŁĄCZNY\\n\\nW IMIENIU\\n\\nRZECZYPOSPOLITEJ ...\n42\n15/351000/0001506/K\n\n\n1\n150515000003506_VII_Ka_000726_2013_Uz_2013-09-...\nVII Ka 726/13\n2013-09-04 02:00:00.0 CEST\n2014-02-05 19:15:04.0 CET\n2014-09-07 10:18:28.0 CEST\n15051500\n3506\nSENTENCE, REASON\nSygn. akt VII Ka 726/13 WYROK W IMIENIU RZECZY...\n&lt;?xml version='1.0' encoding='UTF-8'?&gt;\\n&lt;xPart...\n...\n[Art.437§1 Kpk]\nWioletta Suraj\nsekr.sądowy Elżbieta Łotowska\n[Ustawa z dnia 26 maja 1982 r. - Prawo o adwok...\nRafał Banaszewski\n[Postępowanie Odwoławcze]\n18\nSygn. akt VII Ka 726/13\\n\\nWYROK\\nW IMIENIU RZ...\n726\n15/051500/0003506/Ka\n\n\n\n\n2 rows × 23 columns\n\n\n\n\njudgements_retrieved_informations = chain.batch(\n    [\n        {\"LANGUAGE\": LANGUAGE, \"TEXT\": judgement[\"text\"], \"SCHEMA\": EXAMPLE_SCHEMA}\n        for judgement in judgements\n    ]\n)\n\n\n# add list of retrieved informations to each judgement to the data frame df but treat each key in dict as a new column\nfrom tqdm import tqdm\n\nfor key in tqdm(judgements_retrieved_informations[0].keys(), desc=\"Adding columns to DataFrame\"):\n    df[key] = [judgement[key] for judgement in judgements_retrieved_informations]\n\nAdding columns to DataFrame: 100%|██████████| 7/7 [00:00&lt;00:00, 2339.83it/s]\n\n\n\ndf.head(2)\n\n\n\n\n\n\n\n\n_id\nsignature\ndate\npublicationDate\nlastUpdate\ncourtId\ndepartmentId\ntype\nexcerpt\ncontent\n...\ntext\nvol_number\nvol_type\nRodzaj_przestepstwa_i_kwalifikacja_prawna\nDodatkowe_okolicznosci\nRodzaj_wyroku\nSankcja_karna\nSrodki_kompensacyjne\nSrodki_karne\nOkolicznosci_zwiazane_z_opisem_czynu\n\n\n\n\n0\n153510000001506_III_K_000042_2014_Uz_2014-05-0...\nIII K 42/14\n2014-05-07 02:00:00.0 CEST\n2014-05-30 20:15:03.0 CEST\n2014-06-17 00:57:36.0 CEST\n15351000\n1506\nSENTENCE\nWYROK ŁĄCZNY W IMIENIU RZECZYPOSPOLITEJ POLSKI...\n&lt;?xml version='1.0' encoding='UTF-8'?&gt;\\n&lt;xPart...\n...\nWYROK ŁĄCZNY\\n\\nW IMIENIU\\n\\nRZECZYPOSPOLITEJ ...\n42\n15/351000/0001506/K\n\n{'recydywa': True, 'w_zwiazku_z_art_207_kk_zne...\nwyrok łączny\n{'wyrok_w_zawieszeniu': False, 'skazujacy_na_k...\n{'czy_jest': False, 'jaka_kwota': 0}\n{'jakie': ''}\n{'stosowanie_przemocy': False, 'grozby_bezpraw...\n\n\n1\n150515000003506_VII_Ka_000726_2013_Uz_2013-09-...\nVII Ka 726/13\n2013-09-04 02:00:00.0 CEST\n2014-02-05 19:15:04.0 CET\n2014-09-07 10:18:28.0 CEST\n15051500\n3506\nSENTENCE, REASON\nSygn. akt VII Ka 726/13 WYROK W IMIENIU RZECZY...\n&lt;?xml version='1.0' encoding='UTF-8'?&gt;\\n&lt;xPart...\n...\nSygn. akt VII Ka 726/13\\n\\nWYROK\\nW IMIENIU RZ...\n726\n15/051500/0003506/Ka\nkradzież z włamaniem\n{'recydywa': True, 'w_zwiazku_z_art_207_kk_zne...\nutrzymanie wyroku w mocy\n{'wyrok_w_zawieszeniu': False, 'skazujacy_na_k...\n{'czy_jest': True, 'jaka_kwota': 3386243}\n{'jakie': ''}\n{'stosowanie_przemocy': False, 'grozby_bezpraw...\n\n\n\n\n2 rows × 30 columns\n\n\n\n\ndf.to_csv(SAMPLE_DATA_PATH / \"judgements-10-konfiskata-sample-with-retrieved-informations.csv\")",
    "crumbs": [
      "Data",
      "Schema-based information retrieval from judgements"
    ]
  },
  {
    "objectID": "Dataset Cards/dataset_description_raw.html",
    "href": "Dataset Cards/dataset_description_raw.html",
    "title": "Dataset Card for JuDDGES/pl-court-raw",
    "section": "",
    "text": "import warnings\n\nimport datasets\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport polars as pl\nimport seaborn as sns\nimport transformers\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\nwarnings.filterwarnings('ignore')\nsns.set_theme(\"notebook\")\ntransformers.logging.set_verbosity_error()\ndatasets.logging.set_verbosity_error()\ndatasets.utils.disable_progress_bars()\n\n\nraw_ds = pl.scan_parquet(source=\"../../data/datasets/pl/raw/*\")\n\n\nStatistics\n\nMissing values\nWe identified 5,725 judgments (approximately 1%) with a missing content field. The root cause of these missing values is unknown and assumed to be due to random errors, as only error codes (e.g. 404) were observed when accessing the API during dataset curation. Given that this represents a very small fraction of the dataset, these missing values are not expected to impact the overall data quality, so we removed these judgments. Additionally, the table below displays the number and proportion of missing values across other fields in the dataset (after removing those with missing content).\n\nnull_count = raw_ds.null_count().collect().to_pandas().T.rename(columns={0: \"Null count\"})\nnull_count.index.name = \"Field name\"\nnull_count[\"Null fraction\"] = (null_count[\"Null count\"] / raw_ds.select(pl.len()).collect().item()).round(2)\n# print(null_count.to_markdown())\n\n\n\n\nField name\nNull count\nNull fraction\n\n\n\n\n_id\n0\n0\n\n\nsignature\n0\n0\n\n\ndate\n0\n0\n\n\npublicationDate\n0\n0\n\n\nlastUpdate\n0\n0\n\n\ncourtId\n0\n0\n\n\ndepartmentId\n0\n0\n\n\ntype\n0\n0\n\n\nexcerpt\n0\n0\n\n\ncontent\n0\n0\n\n\nchairman\n47283\n0.12\n\n\ndecision\n408423\n1\n\n\njudges\n39772\n0.1\n\n\nlegalBases\n113534\n0.28\n\n\npublisher\n609\n0\n\n\nrecorder\n103675\n0.25\n\n\nreferences\n40737\n0.1\n\n\nreviser\n171\n0\n\n\nthemePhrases\n117074\n0.29\n\n\nnum_pages\n0\n0\n\n\ntext\n0\n0\n\n\nvol_number\n0\n0\n\n\nvol_type\n0\n0\n\n\ncourt_name\n605\n0\n\n\ndepartment_name\n605\n0\n\n\ntext_legal_bases\n0\n0\n\n\nthesis\n369092\n0.9\n\n\n\n\n\nAnalysis of selected fields\n\ncourt_distribution = raw_ds.drop_nulls(subset=\"court_name\").select(\"court_name\").group_by(\"court_name\").len().sort(\"len\", descending=True).collect().to_pandas()\nax = sns.histplot(data=court_distribution, x=\"len\", log_scale=True, kde=True)\nax.set(title=\"Distribution of judgments per court\", xlabel=\"#Judgements in single court\", ylabel=\"Count\")\nplt.show()\n\n\njudgements_per_year = raw_ds.select(\"date\").collect()[\"date\"].str.split(\" \").list.get(0).str.to_date().dt.year().value_counts().sort(\"date\").to_pandas()\njudgements_per_year = judgements_per_year[judgements_per_year[\"date\"] &lt; 2024]\n\n_, ax = plt.subplots(1, 1, figsize=(10, 5))\nax = sns.pointplot(data=judgements_per_year, x=\"date\", y=\"count\", linestyles=\"--\", ax=ax)\nax.set(xlabel=\"Year\", ylabel=\"Number of Judgements\", title=\"Yearly Number of Judgements\", yscale=\"log\")\nplt.xticks(rotation=90)\nplt.show()\n\n\ntypes = raw_ds.fill_null(value=\"&lt;null&gt;\").select(\"type\").group_by(\"type\").len().sort(\"len\", descending=True).collect().to_pandas()\n\n_, ax = plt.subplots(1, 1, figsize=(8, 8))\nax = sns.barplot(data=types, x=\"len\", y=\"type\", errorbar=None, ax=ax)\nax.set(xlabel=\"Count\", ylabel=\"Type\", title=\"Judgement types cardinality\", xscale=\"log\")\nplt.show()\n\n\nnum_judges = raw_ds.with_columns([pl.col(\"judges\").list.len().alias(\"num_judges\")]).select(\"num_judges\").sort(\"num_judges\").collect().to_pandas()\nax = sns.histplot(data=num_judges, x=\"num_judges\", bins=num_judges[\"num_judges\"].nunique())\nax.set(xlabel=\"#Judges per judgement\", ylabel=\"Count\", yscale=\"log\", title=\"#Judges per single judgement\")\nplt.show()\n\n\nnum_lb = raw_ds.with_columns([pl.col(\"legalBases\").list.len().alias(\"num_lb\")]).select(\"num_lb\").sort(\"num_lb\").collect().to_pandas()\nax = sns.histplot(data=num_lb, x=\"num_lb\", bins=num_lb[\"num_lb\"].nunique())\nax.set(xlabel=\"#Legal bases\", ylabel=\"Count\", yscale=\"log\", title=\"#Legal bases per judgement\")\nplt.show()\n\n\nraw_text_ds = load_dataset(\"parquet\", data_dir=\"../../data/datasets/pl/raw/\", columns=[\"_id\", \"text\"])\nraw_text_ds = raw_text_ds.filter(lambda x: x[\"text\"] is not None)\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n\ndef tokenize(batch: dict[str, list]) -&gt; list[int]: \n    tokenized = tokenizer(batch[\"text\"], add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False, return_length=True)\n    return {\"length\": tokenized[\"length\"]}\n\nraw_text_ds = raw_text_ds.map(tokenize, batched=True, batch_size=16, remove_columns=[\"text\"], num_proc=20)\n\n\njudgement_len = raw_text_ds[\"train\"].to_pandas()\n\nax = sns.histplot(data=judgement_len, x=\"length\", bins=50)\nax.set(xlabel=\"#Tokens\", ylabel=\"Count\", title=\"#Tokens distribution in judgements (llama-3 tokenizer)\", yscale=\"log\")\nax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x/1_000)}k'))\nplt.show()\n\n\nper_type_tokens = raw_ds.fill_null(value=\"&lt;null&gt;\").select([\"_id\", \"type\"]).collect().to_pandas().set_index(\"_id\").join(judgement_len.set_index(\"_id\"))\n\n_, ax = plt.subplots(1, 1, figsize=(10, 10))\nax = sns.boxenplot(data=per_type_tokens, y=\"type\", x=\"length\")\nax.set(xscale=\"log\", title=\"Judgement token count per type\", xlabel=\"#Tokens\", ylabel=\"Type\")\nplt.show()",
    "crumbs": [
      "Dataset Cards",
      "Dataset Card for [JuDDGES/pl-court-raw](https://huggingface.co/datasets/JuDDGES/pl-court-raw)"
    ]
  }
]