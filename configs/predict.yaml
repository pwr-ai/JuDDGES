defaults:
  - llm: ???
  - dataset: ???
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

llm:
  batch_size: 1 # always use the same batch_size for reproducibility

device_map: 'auto'
output_file: data/experiments/predict/raw/${hydra:runtime.choices.dataset}/${hydra:runtime.choices.llm}/outputs_${random_seed}.json
truncate_context: True
generate_kwargs:
  max_new_tokens: ${dataset.max_output_tokens}
  do_sample: true
  temperature: 0.1

random_seed: ???

hydra:
  output_subdir: null
  run:
    dir: .
